{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Model for Sentence Categorization\n",
    "\n",
    "A Neural Network model to help classify sentences as important, or not important enough to be part of a summary\n",
    "\n",
    "Built using Keras\n",
    "\n",
    "https://towardsdatascience.com/building-a-deep-learning-model-using-keras-1548ca149d37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = join(\"..\", \"feature_extraction\", \"feature_outputs\")\n",
    "DATA_FILES_DIR = join(\"..\", \"feature_extraction\", \"data_files\")\n",
    "sentence_vectors_filename = join(FEATURES_DIR, \"sentence_vectors.csv\")\n",
    "summarized_chat_log_ids_filename = join(DATA_FILES_DIR, \"summarized_chat_log_ids.csv\")\n",
    "summarized_chat_date_partitions_filename = join(\n",
    "    DATA_FILES_DIR, \"summarized_chat_date_partitions_cumulative_count.csv\"\n",
    ")\n",
    "concatenated_vectors_filename = join(DATA_FILES_DIR, \"summarized_concatenated_vectors_window_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data using pandas. This takes a couple of seconds\n",
    "# sentence_vectors_df = pd.read_csv(sentence_vectors_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659165, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.661401e-11</td>\n",
       "      <td>4.864283e-10</td>\n",
       "      <td>2.155568e-09</td>\n",
       "      <td>2.559706e-09</td>\n",
       "      <td>2.042709e-09</td>\n",
       "      <td>-9.672571e-10</td>\n",
       "      <td>-1.011755e-09</td>\n",
       "      <td>-7.997459e-10</td>\n",
       "      <td>4.663964e-10</td>\n",
       "      <td>9.187571e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407428e-10</td>\n",
       "      <td>2.914283e-09</td>\n",
       "      <td>-2.747660e-10</td>\n",
       "      <td>4.775819e-10</td>\n",
       "      <td>-2.102210e-10</td>\n",
       "      <td>2.105973e-09</td>\n",
       "      <td>1.021558e-09</td>\n",
       "      <td>2.252703e-10</td>\n",
       "      <td>1.863019e-10</td>\n",
       "      <td>8.672187e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022276e-10</td>\n",
       "      <td>-1.955946e-09</td>\n",
       "      <td>1.327970e-09</td>\n",
       "      <td>1.232455e-09</td>\n",
       "      <td>2.482607e-09</td>\n",
       "      <td>-2.743914e-10</td>\n",
       "      <td>-1.086364e-09</td>\n",
       "      <td>-2.488646e-10</td>\n",
       "      <td>1.262163e-09</td>\n",
       "      <td>9.180705e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.610669e-10</td>\n",
       "      <td>-1.520207e-09</td>\n",
       "      <td>8.983655e-10</td>\n",
       "      <td>8.465219e-10</td>\n",
       "      <td>3.878689e-11</td>\n",
       "      <td>2.797304e-09</td>\n",
       "      <td>1.089229e-10</td>\n",
       "      <td>1.791956e-09</td>\n",
       "      <td>7.814260e-10</td>\n",
       "      <td>-5.340539e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.006117e-09</td>\n",
       "      <td>1.308245e-09</td>\n",
       "      <td>-1.726347e-09</td>\n",
       "      <td>-2.326718e-09</td>\n",
       "      <td>2.644977e-09</td>\n",
       "      <td>-6.860966e-09</td>\n",
       "      <td>-2.840772e-09</td>\n",
       "      <td>-1.275456e-09</td>\n",
       "      <td>-3.629866e-09</td>\n",
       "      <td>2.648799e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.186932e-10</td>\n",
       "      <td>-4.387442e-09</td>\n",
       "      <td>-4.779804e-09</td>\n",
       "      <td>1.756883e-09</td>\n",
       "      <td>1.552142e-09</td>\n",
       "      <td>-1.799109e-09</td>\n",
       "      <td>-2.763327e-09</td>\n",
       "      <td>-1.287349e-09</td>\n",
       "      <td>7.786218e-11</td>\n",
       "      <td>3.528413e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.685328e-11</td>\n",
       "      <td>-2.522545e-09</td>\n",
       "      <td>2.219794e-09</td>\n",
       "      <td>2.225063e-09</td>\n",
       "      <td>1.722988e-09</td>\n",
       "      <td>1.846407e-09</td>\n",
       "      <td>-4.757319e-10</td>\n",
       "      <td>-1.983456e-09</td>\n",
       "      <td>8.535619e-10</td>\n",
       "      <td>8.168705e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.590122e-10</td>\n",
       "      <td>-2.089154e-09</td>\n",
       "      <td>9.565531e-10</td>\n",
       "      <td>-2.301774e-10</td>\n",
       "      <td>7.218851e-10</td>\n",
       "      <td>3.257327e-09</td>\n",
       "      <td>-9.246197e-10</td>\n",
       "      <td>1.512120e-09</td>\n",
       "      <td>2.114480e-09</td>\n",
       "      <td>9.441023e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.038918e-10</td>\n",
       "      <td>-3.730123e-10</td>\n",
       "      <td>-1.157119e-09</td>\n",
       "      <td>6.397932e-10</td>\n",
       "      <td>5.314133e-09</td>\n",
       "      <td>-8.230628e-09</td>\n",
       "      <td>-1.027282e-09</td>\n",
       "      <td>-5.655329e-09</td>\n",
       "      <td>-4.317935e-09</td>\n",
       "      <td>4.408029e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600469e-09</td>\n",
       "      <td>-3.578085e-09</td>\n",
       "      <td>-8.405977e-10</td>\n",
       "      <td>6.335257e-09</td>\n",
       "      <td>-3.260453e-09</td>\n",
       "      <td>-5.920390e-10</td>\n",
       "      <td>-2.368964e-09</td>\n",
       "      <td>-2.441857e-09</td>\n",
       "      <td>2.245674e-09</td>\n",
       "      <td>2.572043e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2             3             4             5  \\\n",
       "0  2.661401e-11  4.864283e-10  2.155568e-09  2.559706e-09  2.042709e-09   \n",
       "1  1.022276e-10 -1.955946e-09  1.327970e-09  1.232455e-09  2.482607e-09   \n",
       "2  5.006117e-09  1.308245e-09 -1.726347e-09 -2.326718e-09  2.644977e-09   \n",
       "3 -6.685328e-11 -2.522545e-09  2.219794e-09  2.225063e-09  1.722988e-09   \n",
       "4 -1.038918e-10 -3.730123e-10 -1.157119e-09  6.397932e-10  5.314133e-09   \n",
       "\n",
       "              6             7             8             9            10  ...  \\\n",
       "0 -9.672571e-10 -1.011755e-09 -7.997459e-10  4.663964e-10  9.187571e-10  ...   \n",
       "1 -2.743914e-10 -1.086364e-09 -2.488646e-10  1.262163e-09  9.180705e-10  ...   \n",
       "2 -6.860966e-09 -2.840772e-09 -1.275456e-09 -3.629866e-09  2.648799e-09  ...   \n",
       "3  1.846407e-09 -4.757319e-10 -1.983456e-09  8.535619e-10  8.168705e-10  ...   \n",
       "4 -8.230628e-09 -1.027282e-09 -5.655329e-09 -4.317935e-09  4.408029e-09  ...   \n",
       "\n",
       "            141           142           143           144           145  \\\n",
       "0  1.407428e-10  2.914283e-09 -2.747660e-10  4.775819e-10 -2.102210e-10   \n",
       "1 -6.610669e-10 -1.520207e-09  8.983655e-10  8.465219e-10  3.878689e-11   \n",
       "2 -4.186932e-10 -4.387442e-09 -4.779804e-09  1.756883e-09  1.552142e-09   \n",
       "3  3.590122e-10 -2.089154e-09  9.565531e-10 -2.301774e-10  7.218851e-10   \n",
       "4  1.600469e-09 -3.578085e-09 -8.405977e-10  6.335257e-09 -3.260453e-09   \n",
       "\n",
       "            146           147           148           149           150  \n",
       "0  2.105973e-09  1.021558e-09  2.252703e-10  1.863019e-10  8.672187e-10  \n",
       "1  2.797304e-09  1.089229e-10  1.791956e-09  7.814260e-10 -5.340539e-10  \n",
       "2 -1.799109e-09 -2.763327e-09 -1.287349e-09  7.786218e-11  3.528413e-09  \n",
       "3  3.257327e-09 -9.246197e-10  1.512120e-09  2.114480e-09  9.441023e-11  \n",
       "4 -5.920390e-10 -2.368964e-09 -2.441857e-09  2.245674e-09  2.572043e-09  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentence_vectors_df.shape)\n",
    "sentence_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_chat_log_ids = pd.read_csv(\n",
    "    summarized_chat_log_ids_filename,\n",
    "    names = [\"log_id\", \"is_summary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20715, 2)\n",
      "   log_id  is_summary\n",
      "0   85350           0\n",
      "1   85351           0\n",
      "2   85352           0\n",
      "3   85353           0\n",
      "4   85354           0\n",
      "       log_id  is_summary\n",
      "20710  624000           0\n",
      "20711  624001           0\n",
      "20712  624002           0\n",
      "20713  624003           0\n",
      "20714  624004           0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 85350,  85351,  85352, ..., 624002, 624003, 624004])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(summarized_chat_log_ids.shape)\n",
    "print(summarized_chat_log_ids.head())\n",
    "print(summarized_chat_log_ids.tail())\n",
    "summarized_chat_log_ids_array = np.array(summarized_chat_log_ids.log_id)\n",
    "summarized_chat_log_ids_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20715, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624000</th>\n",
       "      <td>-2.839511e-10</td>\n",
       "      <td>-5.254820e-10</td>\n",
       "      <td>1.282804e-09</td>\n",
       "      <td>2.894893e-09</td>\n",
       "      <td>5.128183e-09</td>\n",
       "      <td>1.821765e-09</td>\n",
       "      <td>5.974847e-10</td>\n",
       "      <td>2.075842e-10</td>\n",
       "      <td>4.215045e-10</td>\n",
       "      <td>1.692410e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.091932e-10</td>\n",
       "      <td>-6.648306e-10</td>\n",
       "      <td>1.652480e-09</td>\n",
       "      <td>-2.089382e-09</td>\n",
       "      <td>-9.435743e-10</td>\n",
       "      <td>1.338131e-10</td>\n",
       "      <td>7.924803e-10</td>\n",
       "      <td>-1.113637e-09</td>\n",
       "      <td>-5.985640e-10</td>\n",
       "      <td>1.253104e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624001</th>\n",
       "      <td>1.444210e-09</td>\n",
       "      <td>3.307301e-09</td>\n",
       "      <td>2.111036e-09</td>\n",
       "      <td>-5.132918e-09</td>\n",
       "      <td>6.891240e-09</td>\n",
       "      <td>-6.123556e-09</td>\n",
       "      <td>2.262492e-09</td>\n",
       "      <td>2.808561e-09</td>\n",
       "      <td>4.064432e-10</td>\n",
       "      <td>-1.065157e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.181971e-09</td>\n",
       "      <td>-2.439298e-10</td>\n",
       "      <td>-2.457866e-09</td>\n",
       "      <td>-2.707327e-09</td>\n",
       "      <td>3.744598e-09</td>\n",
       "      <td>-4.807546e-09</td>\n",
       "      <td>3.496832e-09</td>\n",
       "      <td>-1.543574e-09</td>\n",
       "      <td>3.499615e-09</td>\n",
       "      <td>2.147703e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624002</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624003</th>\n",
       "      <td>1.458535e-09</td>\n",
       "      <td>-5.703304e-11</td>\n",
       "      <td>-5.895193e-10</td>\n",
       "      <td>-1.133689e-09</td>\n",
       "      <td>2.171077e-10</td>\n",
       "      <td>2.118639e-09</td>\n",
       "      <td>-4.534608e-09</td>\n",
       "      <td>3.737758e-09</td>\n",
       "      <td>-1.644037e-09</td>\n",
       "      <td>-2.644024e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.473653e-09</td>\n",
       "      <td>2.106356e-09</td>\n",
       "      <td>3.655724e-09</td>\n",
       "      <td>-7.238658e-10</td>\n",
       "      <td>-2.371045e-09</td>\n",
       "      <td>1.605171e-09</td>\n",
       "      <td>-7.973208e-10</td>\n",
       "      <td>2.627538e-09</td>\n",
       "      <td>2.332013e-09</td>\n",
       "      <td>-3.632736e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624004</th>\n",
       "      <td>5.430142e-10</td>\n",
       "      <td>-2.819028e-10</td>\n",
       "      <td>-7.516691e-11</td>\n",
       "      <td>2.239415e-09</td>\n",
       "      <td>-1.150621e-09</td>\n",
       "      <td>6.923654e-10</td>\n",
       "      <td>1.881467e-09</td>\n",
       "      <td>-9.825994e-11</td>\n",
       "      <td>2.935388e-10</td>\n",
       "      <td>-7.778984e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.997935e-10</td>\n",
       "      <td>-4.273020e-11</td>\n",
       "      <td>-6.497489e-10</td>\n",
       "      <td>4.892752e-10</td>\n",
       "      <td>-8.289923e-10</td>\n",
       "      <td>-4.780643e-10</td>\n",
       "      <td>-4.995222e-10</td>\n",
       "      <td>-1.426832e-09</td>\n",
       "      <td>-1.326889e-09</td>\n",
       "      <td>-6.566220e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1             2             3             4             5  \\\n",
       "624000 -2.839511e-10 -5.254820e-10  1.282804e-09  2.894893e-09  5.128183e-09   \n",
       "624001  1.444210e-09  3.307301e-09  2.111036e-09 -5.132918e-09  6.891240e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  1.458535e-09 -5.703304e-11 -5.895193e-10 -1.133689e-09  2.171077e-10   \n",
       "624004  5.430142e-10 -2.819028e-10 -7.516691e-11  2.239415e-09 -1.150621e-09   \n",
       "\n",
       "                   6             7             8             9            10  \\\n",
       "624000  1.821765e-09  5.974847e-10  2.075842e-10  4.215045e-10  1.692410e-09   \n",
       "624001 -6.123556e-09  2.262492e-09  2.808561e-09  4.064432e-10 -1.065157e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  2.118639e-09 -4.534608e-09  3.737758e-09 -1.644037e-09 -2.644024e-09   \n",
       "624004  6.923654e-10  1.881467e-09 -9.825994e-11  2.935388e-10 -7.778984e-10   \n",
       "\n",
       "        ...           141           142           143           144  \\\n",
       "624000  ...  5.091932e-10 -6.648306e-10  1.652480e-09 -2.089382e-09   \n",
       "624001  ...  2.181971e-09 -2.439298e-10 -2.457866e-09 -2.707327e-09   \n",
       "624002  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  ... -2.473653e-09  2.106356e-09  3.655724e-09 -7.238658e-10   \n",
       "624004  ...  5.997935e-10 -4.273020e-11 -6.497489e-10  4.892752e-10   \n",
       "\n",
       "                 145           146           147           148           149  \\\n",
       "624000 -9.435743e-10  1.338131e-10  7.924803e-10 -1.113637e-09 -5.985640e-10   \n",
       "624001  3.744598e-09 -4.807546e-09  3.496832e-09 -1.543574e-09  3.499615e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003 -2.371045e-09  1.605171e-09 -7.973208e-10  2.627538e-09  2.332013e-09   \n",
       "624004 -8.289923e-10 -4.780643e-10 -4.995222e-10 -1.426832e-09 -1.326889e-09   \n",
       "\n",
       "                 150  \n",
       "624000  1.253104e-09  \n",
       "624001  2.147703e-09  \n",
       "624002  0.000000e+00  \n",
       "624003 -3.632736e-09  \n",
       "624004 -6.566220e-10  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_sentence_vectors_df = sentence_vectors_df.filter(summarized_chat_log_ids_array, axis=0)\n",
    "summarized_num_of_columns = summarized_sentence_vectors_df.shape[0]\n",
    "# summarized_sentence_vectors_df[\"index\"] = [num for num in range(summarized_num_of_columns)]\n",
    "# summarized_sentence_vectors_df.set_index([\"index\"])\n",
    "# summarized_sentence_vectors_df.reset_index\n",
    "# summarized_sentence_vectors_df.insert(0, \"index\", range(summarized_num_of_columns))\n",
    "print(summarized_sentence_vectors_df.shape)\n",
    "summarized_sentence_vectors_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_chat_date_partitions = pd.read_csv(summarized_chat_date_partitions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_log_id</th>\n",
       "      <th>date_of_log</th>\n",
       "      <th>chat_line_count</th>\n",
       "      <th>cumulative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>473197</td>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>1990</td>\n",
       "      <td>16079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>495175</td>\n",
       "      <td>2001-11-13</td>\n",
       "      <td>1051</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>497259</td>\n",
       "      <td>2001-11-14</td>\n",
       "      <td>536</td>\n",
       "      <td>17666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>526307</td>\n",
       "      <td>2001-11-15</td>\n",
       "      <td>1053</td>\n",
       "      <td>18719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>531627</td>\n",
       "      <td>2001-11-12</td>\n",
       "      <td>1348</td>\n",
       "      <td>20067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>579591</td>\n",
       "      <td>2001-10-24</td>\n",
       "      <td>162</td>\n",
       "      <td>20229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>586206</td>\n",
       "      <td>2001-10-23</td>\n",
       "      <td>165</td>\n",
       "      <td>20394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>623684</td>\n",
       "      <td>2001-10-25</td>\n",
       "      <td>321</td>\n",
       "      <td>20715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_log_id date_of_log  chat_line_count  cumulative_count\n",
       "19      473197  2001-11-07             1990             16079\n",
       "20      495175  2001-11-13             1051             17130\n",
       "21      497259  2001-11-14              536             17666\n",
       "22      526307  2001-11-15             1053             18719\n",
       "23      531627  2001-11-12             1348             20067\n",
       "24      579591  2001-10-24              162             20229\n",
       "25      586206  2001-10-23              165             20394\n",
       "26      623684  2001-10-25              321             20715"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_chat_date_partitions.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the first chat log id for the third last chat date. Use the last three chat log dates for testing. The rest to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20067"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_for_validation_test_split = summarized_chat_date_partitions.tail(4)[\"cumulative_count\"]\n",
    "index_for_validation_test_split = index_for_validation_test_split.values[0]\n",
    "index_for_train_validation_split = summarized_chat_date_partitions.tail(8)[\"cumulative_count\"]\n",
    "index_for_train_validation_split = index_for_train_validation_split.values[0]\n",
    "print(index_for_train_validation_split)\n",
    "index_for_validation_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate sentence vectors for context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_sentence_vectors(data_values, window):\n",
    "    number_of_rows, number_of_columns = data_values.shape\n",
    "    eventual_number_of_columns = number_of_columns +(number_of_columns * window * 2)\n",
    "    new_np_data = np.array([]).reshape(0, eventual_number_of_columns)\n",
    "    \n",
    "    for index in range(data_values.shape[0]):\n",
    "        first_index = index - window\n",
    "        last_index = index + window\n",
    "        start_padding = []\n",
    "        end_padding = []\n",
    "        \n",
    "        if first_index < 0:\n",
    "            start_padding = np.zeros((abs(first_index), number_of_columns))\n",
    "            first_index = 0\n",
    "        if last_index >= number_of_rows:\n",
    "            end_padding = np.zeros((((last_index - number_of_rows) + 1), number_of_columns))\n",
    "            last_index = number_of_rows - 1\n",
    "            \n",
    "        concatenated_row = data_values[first_index:last_index+1]\n",
    "        # print(\"\\n\", index, \"\\n\", concatenated_row, start_padding, \"\\n\\n\")\n",
    "        if len(start_padding) > 0:\n",
    "            # print(start_padding.shape, data_values[first_index: first_index+1].shape)\n",
    "            concatenated_row = np.concatenate((start_padding, concatenated_row))\n",
    "        if len(end_padding) > 0:\n",
    "            # print(end_padding.shape, data_values[first_index: first_index+1].shape)\n",
    "            concatenated_row = np.concatenate((concatenated_row, end_padding))\n",
    "        concatenated_row = concatenated_row.ravel()\n",
    "        # print(index, concatenated_row, \"\\n\\n\")\n",
    "        # print(concatenated_row.shape, new_np_data.shape)\n",
    "        new_np_data = np.concatenate((new_np_data, concatenated_row))\n",
    "    return pd.DataFrame(new_np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.291534423828125e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# summarized_sentence_vectors_array = summarized_sentence_vectors_df.values\n",
    "context_window = 5\n",
    "\n",
    "# This takes about 40 minutes, or 2386.799 seconds\n",
    "# concatenated_sentence_vectors_df = concatenate_sentence_vectors(summarized_sentence_vectors_array, context_window)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_sentence_vectors_df = pd.read_csv(concatenated_vectors_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_sentence_vectors_df = concatenated_sentence_vectors_df.drop(columns=[0])\n",
    "# concatenated_sentence_vectors_df.to_csv(concatenated_vectors_filename)\n",
    "# concatenated_sentence_vectors_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_sentence_vectors_df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_sentence_vectors_df = concatenated_sentence_vectors_df.drop(columns=[\"Unnamed: 0\"])\n",
    "# concatenated_sentence_vectors_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20715, 150)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624000</th>\n",
       "      <td>-2.839511e-10</td>\n",
       "      <td>-5.254820e-10</td>\n",
       "      <td>1.282804e-09</td>\n",
       "      <td>2.894893e-09</td>\n",
       "      <td>5.128183e-09</td>\n",
       "      <td>1.821765e-09</td>\n",
       "      <td>5.974847e-10</td>\n",
       "      <td>2.075842e-10</td>\n",
       "      <td>4.215045e-10</td>\n",
       "      <td>1.692410e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>5.091932e-10</td>\n",
       "      <td>-6.648306e-10</td>\n",
       "      <td>1.652480e-09</td>\n",
       "      <td>-2.089382e-09</td>\n",
       "      <td>-9.435743e-10</td>\n",
       "      <td>1.338131e-10</td>\n",
       "      <td>7.924803e-10</td>\n",
       "      <td>-1.113637e-09</td>\n",
       "      <td>-5.985640e-10</td>\n",
       "      <td>1.253104e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624001</th>\n",
       "      <td>1.444210e-09</td>\n",
       "      <td>3.307301e-09</td>\n",
       "      <td>2.111036e-09</td>\n",
       "      <td>-5.132918e-09</td>\n",
       "      <td>6.891240e-09</td>\n",
       "      <td>-6.123556e-09</td>\n",
       "      <td>2.262492e-09</td>\n",
       "      <td>2.808561e-09</td>\n",
       "      <td>4.064432e-10</td>\n",
       "      <td>-1.065157e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.181971e-09</td>\n",
       "      <td>-2.439298e-10</td>\n",
       "      <td>-2.457866e-09</td>\n",
       "      <td>-2.707327e-09</td>\n",
       "      <td>3.744598e-09</td>\n",
       "      <td>-4.807546e-09</td>\n",
       "      <td>3.496832e-09</td>\n",
       "      <td>-1.543574e-09</td>\n",
       "      <td>3.499615e-09</td>\n",
       "      <td>2.147703e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624002</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624003</th>\n",
       "      <td>1.458535e-09</td>\n",
       "      <td>-5.703304e-11</td>\n",
       "      <td>-5.895193e-10</td>\n",
       "      <td>-1.133689e-09</td>\n",
       "      <td>2.171077e-10</td>\n",
       "      <td>2.118639e-09</td>\n",
       "      <td>-4.534608e-09</td>\n",
       "      <td>3.737758e-09</td>\n",
       "      <td>-1.644037e-09</td>\n",
       "      <td>-2.644024e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.473653e-09</td>\n",
       "      <td>2.106356e-09</td>\n",
       "      <td>3.655724e-09</td>\n",
       "      <td>-7.238658e-10</td>\n",
       "      <td>-2.371045e-09</td>\n",
       "      <td>1.605171e-09</td>\n",
       "      <td>-7.973208e-10</td>\n",
       "      <td>2.627538e-09</td>\n",
       "      <td>2.332013e-09</td>\n",
       "      <td>-3.632736e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624004</th>\n",
       "      <td>5.430142e-10</td>\n",
       "      <td>-2.819028e-10</td>\n",
       "      <td>-7.516691e-11</td>\n",
       "      <td>2.239415e-09</td>\n",
       "      <td>-1.150621e-09</td>\n",
       "      <td>6.923654e-10</td>\n",
       "      <td>1.881467e-09</td>\n",
       "      <td>-9.825994e-11</td>\n",
       "      <td>2.935388e-10</td>\n",
       "      <td>-7.778984e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.997935e-10</td>\n",
       "      <td>-4.273020e-11</td>\n",
       "      <td>-6.497489e-10</td>\n",
       "      <td>4.892752e-10</td>\n",
       "      <td>-8.289923e-10</td>\n",
       "      <td>-4.780643e-10</td>\n",
       "      <td>-4.995222e-10</td>\n",
       "      <td>-1.426832e-09</td>\n",
       "      <td>-1.326889e-09</td>\n",
       "      <td>-6.566220e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   1             2             3             4             5  \\\n",
       "624000 -2.839511e-10 -5.254820e-10  1.282804e-09  2.894893e-09  5.128183e-09   \n",
       "624001  1.444210e-09  3.307301e-09  2.111036e-09 -5.132918e-09  6.891240e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  1.458535e-09 -5.703304e-11 -5.895193e-10 -1.133689e-09  2.171077e-10   \n",
       "624004  5.430142e-10 -2.819028e-10 -7.516691e-11  2.239415e-09 -1.150621e-09   \n",
       "\n",
       "                   6             7             8             9            10  \\\n",
       "624000  1.821765e-09  5.974847e-10  2.075842e-10  4.215045e-10  1.692410e-09   \n",
       "624001 -6.123556e-09  2.262492e-09  2.808561e-09  4.064432e-10 -1.065157e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  2.118639e-09 -4.534608e-09  3.737758e-09 -1.644037e-09 -2.644024e-09   \n",
       "624004  6.923654e-10  1.881467e-09 -9.825994e-11  2.935388e-10 -7.778984e-10   \n",
       "\n",
       "        ...           141           142           143           144  \\\n",
       "624000  ...  5.091932e-10 -6.648306e-10  1.652480e-09 -2.089382e-09   \n",
       "624001  ...  2.181971e-09 -2.439298e-10 -2.457866e-09 -2.707327e-09   \n",
       "624002  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003  ... -2.473653e-09  2.106356e-09  3.655724e-09 -7.238658e-10   \n",
       "624004  ...  5.997935e-10 -4.273020e-11 -6.497489e-10  4.892752e-10   \n",
       "\n",
       "                 145           146           147           148           149  \\\n",
       "624000 -9.435743e-10  1.338131e-10  7.924803e-10 -1.113637e-09 -5.985640e-10   \n",
       "624001  3.744598e-09 -4.807546e-09  3.496832e-09 -1.543574e-09  3.499615e-09   \n",
       "624002  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "624003 -2.371045e-09  1.605171e-09 -7.973208e-10  2.627538e-09  2.332013e-09   \n",
       "624004 -8.289923e-10 -4.780643e-10 -4.995222e-10 -1.426832e-09 -1.326889e-09   \n",
       "\n",
       "                 150  \n",
       "624000  1.253104e-09  \n",
       "624001  2.147703e-09  \n",
       "624002  0.000000e+00  \n",
       "624003 -3.632736e-09  \n",
       "624004 -6.566220e-10  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(summarized_sentence_vectors_df.shape)\n",
    "summarized_sentence_vectors_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DATA_FILE = join(FEATURES_DIR, \"summarized_chats_features.csv\")\n",
    "# read in data using pandas\n",
    "unnormalized_chat_log_df = pd.read_csv(FEATURES_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85350</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>2.758723</td>\n",
       "      <td>0.788992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85351</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85352</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.180867</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85353</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.499669</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85354</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.295432</td>\n",
       "      <td>0.084493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_id  absolute_sentence_position  sentence_length  \\\n",
       "0   85350                    0.000436                1   \n",
       "1   85351                    0.000871               13   \n",
       "2   85352                    0.001307               10   \n",
       "3   85353                    0.001743                5   \n",
       "4   85354                    0.002179                8   \n",
       "\n",
       "   number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "0                        0           0.6249     0.000789   \n",
       "1                        0           0.0000     0.003486   \n",
       "2                        0           0.0000     0.004054   \n",
       "3                        0           0.0000     0.003645   \n",
       "4                        0           0.2263     0.002310   \n",
       "\n",
       "   normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "0                0.006050     2.758723                0.788992           0  \n",
       "1                0.026734     0.149401                0.042729           0  \n",
       "2                0.031086     0.180867                0.051728           0  \n",
       "3                0.027952     0.499669                0.142905           0  \n",
       "4                0.017715     0.295432                0.084493           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnormalized_chat_log_df.tail()\n",
    "# unnormalized_chat_log_df.insert(0, \"index\", range(unnormalized_chat_log_df.shape[0]))\n",
    "# print(unnormalized_chat_log_df.loc[0:5])\n",
    "unnormalized_chat_log_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20715, 160)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85350</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>2.758723</td>\n",
       "      <td>0.788992</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.032557e-08</td>\n",
       "      <td>4.709798e-09</td>\n",
       "      <td>-7.814833e-08</td>\n",
       "      <td>3.333242e-08</td>\n",
       "      <td>-1.757239e-08</td>\n",
       "      <td>-4.967683e-09</td>\n",
       "      <td>3.275183e-08</td>\n",
       "      <td>-4.288362e-08</td>\n",
       "      <td>2.537755e-09</td>\n",
       "      <td>2.285525e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85351</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.880125e-08</td>\n",
       "      <td>-1.505285e-08</td>\n",
       "      <td>-3.228048e-08</td>\n",
       "      <td>6.559005e-08</td>\n",
       "      <td>2.989873e-08</td>\n",
       "      <td>-2.563377e-08</td>\n",
       "      <td>-3.230809e-08</td>\n",
       "      <td>-1.410832e-08</td>\n",
       "      <td>3.297067e-08</td>\n",
       "      <td>8.902228e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85352</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.180867</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.331976e-08</td>\n",
       "      <td>-2.124629e-08</td>\n",
       "      <td>-5.314322e-09</td>\n",
       "      <td>4.871865e-08</td>\n",
       "      <td>2.572267e-08</td>\n",
       "      <td>-1.130713e-08</td>\n",
       "      <td>-3.515117e-08</td>\n",
       "      <td>2.479115e-08</td>\n",
       "      <td>9.735289e-09</td>\n",
       "      <td>3.229467e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85353</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.499669</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564207e-08</td>\n",
       "      <td>1.737575e-09</td>\n",
       "      <td>2.070995e-08</td>\n",
       "      <td>-6.362434e-10</td>\n",
       "      <td>-2.201059e-08</td>\n",
       "      <td>2.865113e-08</td>\n",
       "      <td>-7.716492e-09</td>\n",
       "      <td>-3.310467e-08</td>\n",
       "      <td>-9.572791e-09</td>\n",
       "      <td>-1.052344e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85354</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.295432</td>\n",
       "      <td>0.084493</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.957617e-11</td>\n",
       "      <td>-1.465501e-10</td>\n",
       "      <td>1.223374e-10</td>\n",
       "      <td>1.708342e-10</td>\n",
       "      <td>3.674844e-10</td>\n",
       "      <td>1.448876e-10</td>\n",
       "      <td>6.751768e-10</td>\n",
       "      <td>1.813555e-10</td>\n",
       "      <td>6.316711e-10</td>\n",
       "      <td>-4.996572e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_id  absolute_sentence_position  sentence_length  \\\n",
       "0   85350                    0.000436                1   \n",
       "1   85351                    0.000871               13   \n",
       "2   85352                    0.001307               10   \n",
       "3   85353                    0.001743                5   \n",
       "4   85354                    0.002179                8   \n",
       "\n",
       "   number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "0                        0           0.6249     0.000789   \n",
       "1                        0           0.0000     0.003486   \n",
       "2                        0           0.0000     0.004054   \n",
       "3                        0           0.0000     0.003645   \n",
       "4                        0           0.2263     0.002310   \n",
       "\n",
       "   normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \\\n",
       "0                0.006050     2.758723                0.788992           0   \n",
       "1                0.026734     0.149401                0.042729           0   \n",
       "2                0.031086     0.180867                0.051728           0   \n",
       "3                0.027952     0.499669                0.142905           0   \n",
       "4                0.017715     0.295432                0.084493           0   \n",
       "\n",
       "   ...           141           142           143           144           145  \\\n",
       "0  ...  5.032557e-08  4.709798e-09 -7.814833e-08  3.333242e-08 -1.757239e-08   \n",
       "1  ...  3.880125e-08 -1.505285e-08 -3.228048e-08  6.559005e-08  2.989873e-08   \n",
       "2  ...  2.331976e-08 -2.124629e-08 -5.314322e-09  4.871865e-08  2.572267e-08   \n",
       "3  ...  2.564207e-08  1.737575e-09  2.070995e-08 -6.362434e-10 -2.201059e-08   \n",
       "4  ...  2.957617e-11 -1.465501e-10  1.223374e-10  1.708342e-10  3.674844e-10   \n",
       "\n",
       "            146           147           148           149           150  \n",
       "0 -4.967683e-09  3.275183e-08 -4.288362e-08  2.537755e-09  2.285525e-08  \n",
       "1 -2.563377e-08 -3.230809e-08 -1.410832e-08  3.297067e-08  8.902228e-08  \n",
       "2 -1.130713e-08 -3.515117e-08  2.479115e-08  9.735289e-09  3.229467e-08  \n",
       "3  2.865113e-08 -7.716492e-09 -3.310467e-08 -9.572791e-09 -1.052344e-08  \n",
       "4  1.448876e-10  6.751768e-10  1.813555e-10  6.316711e-10 -4.996572e-10  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnormalized_merged_log_data_df = pd.merge(\n",
    "    unnormalized_chat_log_df, \n",
    "    summarized_sentence_vectors_df, \n",
    "    left_on=\"log_id\",\n",
    "    right_index=True\n",
    ")\n",
    "print(unnormalized_merged_log_data_df.shape)\n",
    "unnormalized_merged_log_data_df.head()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing The Data\n",
    "Formula to normalize data\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data_max_values = unnormalized_chat_log_df.max()\n",
    "chat_data_min_values = unnormalized_chat_log_df.min()\n",
    "max_number_of_special_terms = chat_data_max_values.number_of_special_terms\n",
    "max_sentence_length = chat_data_max_values.sentence_length\n",
    "min_number_of_special_terms = chat_data_min_values.number_of_special_terms\n",
    "min_sentence_length = chat_data_min_values.sentence_length\n",
    "\n",
    "max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.013699\n",
      "1    0.178082\n",
      "2    0.136986\n",
      "3    0.068493\n",
      "4    0.109589\n",
      "Name: sentence_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85350</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>2.758723</td>\n",
       "      <td>0.788992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85351</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85352</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.180867</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85353</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.499669</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85354</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.295432</td>\n",
       "      <td>0.084493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_id  absolute_sentence_position  sentence_length  \\\n",
       "0   85350                    0.000436         0.013699   \n",
       "1   85351                    0.000871         0.178082   \n",
       "2   85352                    0.001307         0.136986   \n",
       "3   85353                    0.001743         0.068493   \n",
       "4   85354                    0.002179         0.109589   \n",
       "\n",
       "   number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "0                      0.0           0.6249     0.000789   \n",
       "1                      0.0           0.0000     0.003486   \n",
       "2                      0.0           0.0000     0.004054   \n",
       "3                      0.0           0.0000     0.003645   \n",
       "4                      0.0           0.2263     0.002310   \n",
       "\n",
       "   normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "0                0.006050     2.758723                0.788992           0  \n",
       "1                0.026734     0.149401                0.042729           0  \n",
       "2                0.031086     0.180867                0.051728           0  \n",
       "3                0.027952     0.499669                0.142905           0  \n",
       "4                0.017715     0.295432                0.084493           0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_log_df = unnormalized_chat_log_df.copy()\n",
    "chat_log_df.sentence_length = (\n",
    "    chat_log_df.sentence_length - min_sentence_length) / (\n",
    "    max_sentence_length - min_sentence_length)\n",
    "chat_log_df.number_of_special_terms = (\n",
    "    chat_log_df.number_of_special_terms - min_number_of_special_terms) / (\n",
    "    max_number_of_special_terms - min_number_of_special_terms)\n",
    "chat_log_df.reset_index()\n",
    "print(chat_log_df.sentence_length.head())\n",
    "chat_log_df.iloc[0:5]\n",
    "# chat_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16074</th>\n",
       "      <td>475182</td>\n",
       "      <td>0.997990</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.025540</td>\n",
       "      <td>0.200114</td>\n",
       "      <td>0.057232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16075</th>\n",
       "      <td>475183</td>\n",
       "      <td>0.998492</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>2.395763</td>\n",
       "      <td>0.685186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16076</th>\n",
       "      <td>475184</td>\n",
       "      <td>0.998995</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.906608</td>\n",
       "      <td>0.259289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16077</th>\n",
       "      <td>475185</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.034522</td>\n",
       "      <td>1.754785</td>\n",
       "      <td>0.501867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16078</th>\n",
       "      <td>475186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.269295</td>\n",
       "      <td>0.077018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "16074  475182                    0.997990         0.136986   \n",
       "16075  475183                    0.998492         0.013699   \n",
       "16076  475184                    0.998995         0.027397   \n",
       "16077  475185                    0.999497         0.013699   \n",
       "16078  475186                    1.000000         0.082192   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "16074                      0.0           0.2023     0.003331   \n",
       "16075                      0.0           0.0000     0.002157   \n",
       "16076                      0.0           0.2263     0.002054   \n",
       "16077                      0.0           0.6369     0.004502   \n",
       "16078                      0.0           0.2240     0.003923   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "16074                0.025540     0.200114                0.057232           0  \n",
       "16075                0.016537     2.395763                0.685186           0  \n",
       "16076                0.015752     0.906608                0.259289           0  \n",
       "16077                0.034522     1.754785                0.501867           0  \n",
       "16078                0.030084     0.269295                0.077018           0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = chat_log_df.iloc[:index_for_train_validation_split]\n",
    "validation_df = chat_log_df.iloc[index_for_train_validation_split:index_for_validation_test_split]\n",
    "test_df = chat_log_df.iloc[index_for_validation_test_split:]\n",
    "train_df.tail()\n",
    "\n",
    "# Sentence Vectors only\n",
    "# train_vectors_df = summarized_sentence_vectors_df.iloc[:index_for_train_validation_split]\n",
    "# validation_vectors_df = summarized_sentence_vectors_df.iloc[index_for_train_validation_split:index_for_validation_test_split]\n",
    "# test_vectors_df = summarized_sentence_vectors_df.iloc[index_for_validation_test_split:]\n",
    "# train_vectors_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>495175</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.174116</td>\n",
       "      <td>0.049797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16080</th>\n",
       "      <td>495176</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>3.021603</td>\n",
       "      <td>0.864176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16081</th>\n",
       "      <td>495177</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>495178</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.212884</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16083</th>\n",
       "      <td>495179</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.442957</td>\n",
       "      <td>0.126685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "16079  495175                    0.000951         0.150685   \n",
       "16080  495176                    0.001903         0.013699   \n",
       "16081  495177                    0.002854         0.000000   \n",
       "16082  495178                    0.003806         0.136986   \n",
       "16083  495179                    0.004757         0.054795   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "16079                 0.000000           0.4588     0.002049   \n",
       "16080                 0.000000           0.0000     0.000825   \n",
       "16081                 0.000000           0.4588     0.000000   \n",
       "16082                 0.054054           0.0000     0.001636   \n",
       "16083                 0.000000           0.4588     0.001551   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "16079                0.015712     0.174116                0.049797           0  \n",
       "16080                0.006325     3.021603                0.864176           0  \n",
       "16081                0.000000     0.000000                0.000000           0  \n",
       "16082                0.012544     0.212884                0.060885           0  \n",
       "16083                0.011894     0.442957                0.126685           0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>532970</td>\n",
       "      <td>0.997033</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>3.129690</td>\n",
       "      <td>0.895088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20063</th>\n",
       "      <td>532971</td>\n",
       "      <td>0.997774</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.773078</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20064</th>\n",
       "      <td>532972</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.018096</td>\n",
       "      <td>2.527630</td>\n",
       "      <td>0.722900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20065</th>\n",
       "      <td>532973</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.354299</td>\n",
       "      <td>0.101329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20066</th>\n",
       "      <td>532974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>1.144535</td>\n",
       "      <td>0.327336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "20062  532970                    0.997033         0.013699   \n",
       "20063  532971                    0.997774         0.041096   \n",
       "20064  532972                    0.998516         0.013699   \n",
       "20065  532973                    0.999258         0.068493   \n",
       "20066  532974                    1.000000         0.027397   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "20062                      0.0           0.0000     0.001777   \n",
       "20063                      0.0           0.0000     0.004070   \n",
       "20064                      0.0           0.5267     0.002360   \n",
       "20065                      0.0          -0.2500     0.002685   \n",
       "20066                      0.0           0.0000     0.000900   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "20062                0.013628     3.129690                0.895088           0  \n",
       "20063                0.031206     0.773078                0.221100           0  \n",
       "20064                0.018096     2.527630                0.722900           0  \n",
       "20065                0.020592     0.354299                0.101329           0  \n",
       "20066                0.006898     1.144535                0.327336           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>579591</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.100264</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20068</th>\n",
       "      <td>579592</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>1.104758</td>\n",
       "      <td>0.315960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>579593</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.642605</td>\n",
       "      <td>0.183785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>579594</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>579595</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.954243</td>\n",
       "      <td>0.272912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "20067  579591                    0.006173         0.232877   \n",
       "20068  579592                    0.012346         0.027397   \n",
       "20069  579593                    0.018519         0.041096   \n",
       "20070  579594                    0.024691         0.000000   \n",
       "20071  579595                    0.030864         0.027397   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "20067                      0.0           0.5994     0.000609   \n",
       "20068                      0.0          -0.2960     0.000089   \n",
       "20069                      0.0          -0.2960     0.000439   \n",
       "20070                      0.0          -0.4404     0.000000   \n",
       "20071                      0.0           0.0000     0.000553   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "20067                0.004672     0.100264                0.028675           0  \n",
       "20068                0.000686     1.104758                0.315960           0  \n",
       "20069                0.003367     0.642605                0.183785           0  \n",
       "20070                0.000000     0.000000                0.000000           0  \n",
       "20071                0.004243     0.954243                0.272912           0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>624000</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.281268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>624001</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.444846</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20712</th>\n",
       "      <td>624002</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.306102</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>624003</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>624004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>2.205475</td>\n",
       "      <td>0.630764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "20710  624000                    0.987539         0.027397   \n",
       "20711  624001                    0.990654         0.054795   \n",
       "20712  624002                    0.993769         0.095890   \n",
       "20713  624003                    0.996885         0.000000   \n",
       "20714  624004                    1.000000         0.013699   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "20710                      0.0           0.0000     0.000432   \n",
       "20711                      0.0           0.0000     0.000801   \n",
       "20712                      0.0           0.5267     0.001122   \n",
       "20713                      0.0           0.4588     0.000000   \n",
       "20714                      0.0           0.0000     0.000803   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "20710                0.003309     0.983457                0.281268           0  \n",
       "20711                0.006145     0.444846                0.127226           0  \n",
       "20712                0.008603     0.306102                0.087545           0  \n",
       "20713                0.000000     0.000000                0.000000           0  \n",
       "20714                0.006161     2.205475                0.630764           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data has been read in properly\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.788992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.042729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.051728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.142905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.084493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "0                    0.000436         0.013699                      0.0   \n",
       "1                    0.000871         0.178082                      0.0   \n",
       "2                    0.001307         0.136986                      0.0   \n",
       "3                    0.001743         0.068493                      0.0   \n",
       "4                    0.002179         0.109589                      0.0   \n",
       "\n",
       "   sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "0           0.6249                0.006050                0.788992  \n",
       "1           0.0000                0.026734                0.042729  \n",
       "2           0.0000                0.031086                0.051728  \n",
       "3           0.0000                0.027952                0.142905  \n",
       "4           0.2263                0.017715                0.084493  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with all training data except the target column\n",
    "columns_to_drop = [\"log_id\", \"is_summary\", \"mean_tf_idf\", \"mean_tf_isf\"]\n",
    "# Keep only normalized columns\n",
    "train_X = train_df.drop(columns=columns_to_drop)\n",
    "validation_X = validation_df.drop(columns=columns_to_drop)\n",
    "test_X = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "assert train_X.shape[1] == test_X.shape[1] and test_X.shape[1] == validation_X.shape[1] \n",
    "#check that the target variable has been removed\n",
    "print(train_X.shape)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_columns = [str(num) for num in range(1, 151)]\n",
    "train_X_no_vectors = train_X.drop(columns=vector_columns)\n",
    "validation_X_no_vectors = validation_X.drop(columns=vector_columns)\n",
    "test_X_no_vectors = test_X.drop(columns=vector_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.788992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.042729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.051728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.142905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.084493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "0                    0.000436         0.013699                      0.0   \n",
       "1                    0.000871         0.178082                      0.0   \n",
       "2                    0.001307         0.136986                      0.0   \n",
       "3                    0.001743         0.068493                      0.0   \n",
       "4                    0.002179         0.109589                      0.0   \n",
       "\n",
       "   sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "0           0.6249                0.006050                0.788992  \n",
       "1           0.0000                0.026734                0.042729  \n",
       "2           0.0000                0.031086                0.051728  \n",
       "3           0.0000                0.027952                0.142905  \n",
       "4           0.2263                0.017715                0.084493  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X_no_vectors.shape)\n",
    "assert train_X_no_vectors.shape[1] == validation_X_no_vectors.shape[1] \n",
    "assert validation_X_no_vectors.shape[1] == test_X_no_vectors.shape[1]\n",
    "train_X_no_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3988, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16079</th>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.049797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16080</th>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.864176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16081</th>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.060885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16083</th>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.126685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "16079                    0.000951         0.150685                 0.000000   \n",
       "16080                    0.001903         0.013699                 0.000000   \n",
       "16081                    0.002854         0.000000                 0.000000   \n",
       "16082                    0.003806         0.136986                 0.054054   \n",
       "16083                    0.004757         0.054795                 0.000000   \n",
       "\n",
       "       sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "16079           0.4588                0.015712                0.049797  \n",
       "16080           0.0000                0.006325                0.864176  \n",
       "16081           0.4588                0.000000                0.000000  \n",
       "16082           0.0000                0.012544                0.060885  \n",
       "16083           0.4588                0.011894                0.126685  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(validation_X.shape)\n",
    "validation_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.028675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20068</th>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.315960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.183785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.272912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "20067                    0.006173         0.232877                      0.0   \n",
       "20068                    0.012346         0.027397                      0.0   \n",
       "20069                    0.018519         0.041096                      0.0   \n",
       "20070                    0.024691         0.000000                      0.0   \n",
       "20071                    0.030864         0.027397                      0.0   \n",
       "\n",
       "       sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "20067           0.5994                0.004672                0.028675  \n",
       "20068          -0.2960                0.000686                0.315960  \n",
       "20069          -0.2960                0.003367                0.183785  \n",
       "20070          -0.4404                0.000000                0.000000  \n",
       "20071           0.0000                0.004243                0.272912  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.is_summary.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When separating the target column, we need to call the `to_categorical()` function so that column will be `one-hot encoded`. Currently, a chat line that is not a summary is represented with a `0` in the `is_summary` column and a chat line that is a summary is represented with a `1`. With one-hot encoding, the integer will be removed and a binary variable is inputted for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a one hot encoding for the target column\n",
    "train_y = to_categorical(train_df.is_summary)\n",
    "train_y_nums = train_df.is_summary.values\n",
    "validation_y = to_categorical(validation_df.is_summary)\n",
    "validation_y_nums = validation_df.is_summary.values\n",
    "test_y = to_categorical(test_df.is_summary)\n",
    "test_y_nums = test_df.is_summary.values\n",
    "# view one hot encoding numpy array\n",
    "print(train_y_nums)\n",
    "train_y[415: 425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079, 2)\n",
      "(3988, 2)\n",
      "(648, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(validation_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation is `softmax`. Softmax makes the output sum up to `1` so the output can be interpreted as probabilities. The model will then make its prediction based on which option has a higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#get number of columns in training data\n",
    "# n_cols = train_vectors_df.shape[1]\n",
    "n_cols = train_X.shape[1]\n",
    "\n",
    "#add model layers\n",
    "model.add(Dense(n_cols, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,044\n",
      "Trainable params: 11,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `categorical_crossentropy` for our loss function. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
    "\n",
    "We will use the â€˜mean absolute errorâ€™ metric to see the score on the validation set at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using mse as a measure of model performance\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "# early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wcyn/anaconda3/envs/gnue-irc/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 16079 samples, validate on 3988 samples\n",
      "Epoch 1/400\n",
      "16079/16079 [==============================] - 2s 144us/step - loss: 0.1632 - acc: 0.9665 - val_loss: 0.1285 - val_acc: 0.9709\n",
      "Epoch 2/400\n",
      "16079/16079 [==============================] - 2s 106us/step - loss: 0.1345 - acc: 0.9684 - val_loss: 0.1320 - val_acc: 0.9709\n",
      "Epoch 3/400\n",
      "16079/16079 [==============================] - 1s 83us/step - loss: 0.1338 - acc: 0.9684 - val_loss: 0.1284 - val_acc: 0.9709\n",
      "Epoch 4/400\n",
      "16079/16079 [==============================] - 2s 99us/step - loss: 0.1336 - acc: 0.9684 - val_loss: 0.1288 - val_acc: 0.9709\n",
      "Epoch 5/400\n",
      "16079/16079 [==============================] - 1s 80us/step - loss: 0.1334 - acc: 0.9684 - val_loss: 0.1287 - val_acc: 0.9709\n",
      "Epoch 6/400\n",
      "16079/16079 [==============================] - 1s 89us/step - loss: 0.1331 - acc: 0.9684 - val_loss: 0.1291 - val_acc: 0.9709\n",
      "Epoch 7/400\n",
      "16079/16079 [==============================] - 2s 98us/step - loss: 0.1330 - acc: 0.9684 - val_loss: 0.1291 - val_acc: 0.9709\n",
      "Epoch 8/400\n",
      "16079/16079 [==============================] - 2s 98us/step - loss: 0.1325 - acc: 0.9684 - val_loss: 0.1343 - val_acc: 0.9709\n",
      "Epoch 9/400\n",
      "16079/16079 [==============================] - 2s 95us/step - loss: 0.1324 - acc: 0.9684 - val_loss: 0.1286 - val_acc: 0.9709\n",
      "Epoch 10/400\n",
      "16079/16079 [==============================] - 1s 83us/step - loss: 0.1323 - acc: 0.9684 - val_loss: 0.1298 - val_acc: 0.9709\n",
      "Epoch 11/400\n",
      "16079/16079 [==============================] - 2s 95us/step - loss: 0.1324 - acc: 0.9684 - val_loss: 0.1292 - val_acc: 0.9709\n",
      "Epoch 12/400\n",
      "16079/16079 [==============================] - 2s 101us/step - loss: 0.1319 - acc: 0.9684 - val_loss: 0.1286 - val_acc: 0.9709\n",
      "Epoch 13/400\n",
      "16079/16079 [==============================] - 2s 104us/step - loss: 0.1325 - acc: 0.9684 - val_loss: 0.1295 - val_acc: 0.9709\n",
      "Epoch 14/400\n",
      "16079/16079 [==============================] - 2s 108us/step - loss: 0.1321 - acc: 0.9684 - val_loss: 0.1291 - val_acc: 0.9709\n",
      "Epoch 15/400\n",
      "16079/16079 [==============================] - 1s 85us/step - loss: 0.1316 - acc: 0.9684 - val_loss: 0.1293 - val_acc: 0.9709\n",
      "Epoch 16/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1320 - acc: 0.9684 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 17/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1318 - acc: 0.9684 - val_loss: 0.1306 - val_acc: 0.9709\n",
      "Epoch 18/400\n",
      "16079/16079 [==============================] - 1s 86us/step - loss: 0.1315 - acc: 0.9684 - val_loss: 0.1302 - val_acc: 0.9709\n",
      "Epoch 19/400\n",
      "16079/16079 [==============================] - 1s 81us/step - loss: 0.1313 - acc: 0.9684 - val_loss: 0.1298 - val_acc: 0.9709\n",
      "Epoch 20/400\n",
      "16079/16079 [==============================] - 1s 84us/step - loss: 0.1312 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 21/400\n",
      "16079/16079 [==============================] - 1s 82us/step - loss: 0.1310 - acc: 0.9684 - val_loss: 0.1298 - val_acc: 0.9709\n",
      "Epoch 22/400\n",
      "16079/16079 [==============================] - 1s 86us/step - loss: 0.1314 - acc: 0.9684 - val_loss: 0.1353 - val_acc: 0.9709\n",
      "Epoch 23/400\n",
      "16079/16079 [==============================] - 2s 98us/step - loss: 0.1306 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 24/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1308 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 25/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1306 - acc: 0.9684 - val_loss: 0.1291 - val_acc: 0.9709\n",
      "Epoch 26/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1303 - acc: 0.9684 - val_loss: 0.1338 - val_acc: 0.9709\n",
      "Epoch 27/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1307 - acc: 0.9684 - val_loss: 0.1302 - val_acc: 0.9709\n",
      "Epoch 28/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1305 - acc: 0.9684 - val_loss: 0.1292 - val_acc: 0.9709\n",
      "Epoch 29/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1302 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 30/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1306 - acc: 0.9684 - val_loss: 0.1290 - val_acc: 0.9709\n",
      "Epoch 31/400\n",
      "16079/16079 [==============================] - 2s 122us/step - loss: 0.1305 - acc: 0.9684 - val_loss: 0.1286 - val_acc: 0.9709\n",
      "Epoch 32/400\n",
      "16079/16079 [==============================] - 2s 95us/step - loss: 0.1303 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 33/400\n",
      "16079/16079 [==============================] - 2s 101us/step - loss: 0.1305 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 34/400\n",
      "16079/16079 [==============================] - 2s 96us/step - loss: 0.1296 - acc: 0.9684 - val_loss: 0.1358 - val_acc: 0.9709\n",
      "Epoch 35/400\n",
      "16079/16079 [==============================] - 2s 101us/step - loss: 0.1303 - acc: 0.9684 - val_loss: 0.1296 - val_acc: 0.9709\n",
      "Epoch 36/400\n",
      "16079/16079 [==============================] - 2s 114us/step - loss: 0.1300 - acc: 0.9684 - val_loss: 0.1301 - val_acc: 0.9709\n",
      "Epoch 37/400\n",
      "16079/16079 [==============================] - 2s 116us/step - loss: 0.1299 - acc: 0.9684 - val_loss: 0.1295 - val_acc: 0.9709\n",
      "Epoch 38/400\n",
      "16079/16079 [==============================] - 2s 105us/step - loss: 0.1297 - acc: 0.9684 - val_loss: 0.1296 - val_acc: 0.9709\n",
      "Epoch 39/400\n",
      "16079/16079 [==============================] - 1s 92us/step - loss: 0.1295 - acc: 0.9684 - val_loss: 0.1346 - val_acc: 0.9709\n",
      "Epoch 40/400\n",
      "16079/16079 [==============================] - 1s 90us/step - loss: 0.1299 - acc: 0.9684 - val_loss: 0.1288 - val_acc: 0.9709\n",
      "Epoch 41/400\n",
      "16079/16079 [==============================] - 1s 88us/step - loss: 0.1294 - acc: 0.9684 - val_loss: 0.1298 - val_acc: 0.9709\n",
      "Epoch 42/400\n",
      "16079/16079 [==============================] - 2s 109us/step - loss: 0.1300 - acc: 0.9684 - val_loss: 0.1299 - val_acc: 0.9709\n",
      "Epoch 43/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1294 - acc: 0.9684 - val_loss: 0.1311 - val_acc: 0.9709\n",
      "Epoch 44/400\n",
      "16079/16079 [==============================] - 2s 111us/step - loss: 0.1292 - acc: 0.9684 - val_loss: 0.1295 - val_acc: 0.9709\n",
      "Epoch 45/400\n",
      "16079/16079 [==============================] - 2s 97us/step - loss: 0.1293 - acc: 0.9684 - val_loss: 0.1326 - val_acc: 0.9709\n",
      "Epoch 46/400\n",
      "16079/16079 [==============================] - 1s 87us/step - loss: 0.1290 - acc: 0.9684 - val_loss: 0.1310 - val_acc: 0.9709\n",
      "Epoch 47/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1287 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 48/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1287 - acc: 0.9684 - val_loss: 0.1293 - val_acc: 0.9709\n",
      "Epoch 49/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1283 - acc: 0.9684 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Epoch 50/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1283 - acc: 0.9684 - val_loss: 0.1308 - val_acc: 0.9709\n",
      "Epoch 51/400\n",
      "16079/16079 [==============================] - 1s 59us/step - loss: 0.1290 - acc: 0.9684 - val_loss: 0.1320 - val_acc: 0.9709\n",
      "Epoch 52/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1283 - acc: 0.9684 - val_loss: 0.1286 - val_acc: 0.9709\n",
      "Epoch 53/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1289 - acc: 0.9684 - val_loss: 0.1303 - val_acc: 0.9709\n",
      "Epoch 54/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1282 - acc: 0.9684 - val_loss: 0.1319 - val_acc: 0.9709\n",
      "Epoch 55/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1288 - acc: 0.9684 - val_loss: 0.1295 - val_acc: 0.9709\n",
      "Epoch 56/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1280 - acc: 0.9684 - val_loss: 0.1303 - val_acc: 0.9709\n",
      "Epoch 57/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1282 - acc: 0.9684 - val_loss: 0.1296 - val_acc: 0.9709\n",
      "Epoch 58/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1282 - acc: 0.9684 - val_loss: 0.1307 - val_acc: 0.9709\n",
      "Epoch 59/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1280 - acc: 0.9684 - val_loss: 0.1292 - val_acc: 0.9709\n",
      "Epoch 60/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1279 - acc: 0.9684 - val_loss: 0.1310 - val_acc: 0.9709\n",
      "Epoch 61/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1280 - acc: 0.9684 - val_loss: 0.1294 - val_acc: 0.9709\n",
      "Epoch 62/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1284 - acc: 0.9684 - val_loss: 0.1291 - val_acc: 0.9709\n",
      "Epoch 63/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1279 - acc: 0.9684 - val_loss: 0.1294 - val_acc: 0.9709\n",
      "Epoch 64/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1277 - acc: 0.9684 - val_loss: 0.1310 - val_acc: 0.9709\n",
      "Epoch 65/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1277 - acc: 0.9684 - val_loss: 0.1326 - val_acc: 0.9709\n",
      "Epoch 66/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1282 - acc: 0.9684 - val_loss: 0.1301 - val_acc: 0.9709\n",
      "Epoch 67/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1275 - acc: 0.9684 - val_loss: 0.1296 - val_acc: 0.9709\n",
      "Epoch 68/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1279 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 69/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1277 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 70/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1275 - acc: 0.9684 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Epoch 71/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1270 - acc: 0.9684 - val_loss: 0.1314 - val_acc: 0.9709\n",
      "Epoch 72/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1273 - acc: 0.9684 - val_loss: 0.1305 - val_acc: 0.9709\n",
      "Epoch 73/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1276 - acc: 0.9684 - val_loss: 0.1307 - val_acc: 0.9709\n",
      "Epoch 74/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1275 - acc: 0.9684 - val_loss: 0.1299 - val_acc: 0.9709\n",
      "Epoch 75/400\n",
      "16079/16079 [==============================] - 1s 56us/step - loss: 0.1275 - acc: 0.9684 - val_loss: 0.1331 - val_acc: 0.9709\n",
      "Epoch 76/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1274 - acc: 0.9684 - val_loss: 0.1340 - val_acc: 0.9709\n",
      "Epoch 77/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1276 - acc: 0.9684 - val_loss: 0.1330 - val_acc: 0.9709\n",
      "Epoch 78/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1274 - acc: 0.9684 - val_loss: 0.1309 - val_acc: 0.9709\n",
      "Epoch 79/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1273 - acc: 0.9684 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 80/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1275 - acc: 0.9684 - val_loss: 0.1305 - val_acc: 0.9709\n",
      "Epoch 81/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1268 - acc: 0.9684 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Epoch 82/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1274 - acc: 0.9684 - val_loss: 0.1310 - val_acc: 0.9709\n",
      "Epoch 83/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1272 - acc: 0.9684 - val_loss: 0.1325 - val_acc: 0.9709\n",
      "Epoch 84/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1266 - acc: 0.9684 - val_loss: 0.1311 - val_acc: 0.9709\n",
      "Epoch 85/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1267 - acc: 0.9684 - val_loss: 0.1299 - val_acc: 0.9709\n",
      "Epoch 86/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1268 - acc: 0.9684 - val_loss: 0.1301 - val_acc: 0.9709\n",
      "Epoch 87/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1264 - acc: 0.9684 - val_loss: 0.1303 - val_acc: 0.9709\n",
      "Epoch 88/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1265 - acc: 0.9684 - val_loss: 0.1315 - val_acc: 0.9709\n",
      "Epoch 89/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1270 - acc: 0.9684 - val_loss: 0.1332 - val_acc: 0.9709\n",
      "Epoch 90/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1268 - acc: 0.9684 - val_loss: 0.1320 - val_acc: 0.9709\n",
      "Epoch 91/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1268 - acc: 0.9684 - val_loss: 0.1308 - val_acc: 0.9709\n",
      "Epoch 92/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1265 - acc: 0.9684 - val_loss: 0.1304 - val_acc: 0.9709\n",
      "Epoch 93/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1266 - acc: 0.9684 - val_loss: 0.1303 - val_acc: 0.9709\n",
      "Epoch 94/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1264 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 95/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1265 - acc: 0.9684 - val_loss: 0.1308 - val_acc: 0.9709\n",
      "Epoch 96/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1264 - acc: 0.9684 - val_loss: 0.1321 - val_acc: 0.9709\n",
      "Epoch 97/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1262 - acc: 0.9684 - val_loss: 0.1297 - val_acc: 0.9709\n",
      "Epoch 98/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1262 - acc: 0.9684 - val_loss: 0.1302 - val_acc: 0.9709\n",
      "Epoch 99/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1258 - acc: 0.9684 - val_loss: 0.1311 - val_acc: 0.9709\n",
      "Epoch 100/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1262 - acc: 0.9684 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Epoch 101/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1259 - acc: 0.9684 - val_loss: 0.1321 - val_acc: 0.9709\n",
      "Epoch 102/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1261 - acc: 0.9684 - val_loss: 0.1300 - val_acc: 0.9709\n",
      "Epoch 103/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1259 - acc: 0.9684 - val_loss: 0.1319 - val_acc: 0.9709\n",
      "Epoch 104/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1257 - acc: 0.9684 - val_loss: 0.1340 - val_acc: 0.9709\n",
      "Epoch 105/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1252 - acc: 0.9684 - val_loss: 0.1335 - val_acc: 0.9709\n",
      "Epoch 106/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1260 - acc: 0.9684 - val_loss: 0.1313 - val_acc: 0.9709\n",
      "Epoch 107/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1256 - acc: 0.9684 - val_loss: 0.1304 - val_acc: 0.9709\n",
      "Epoch 108/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1255 - acc: 0.9684 - val_loss: 0.1346 - val_acc: 0.9709\n",
      "Epoch 109/400\n",
      "16079/16079 [==============================] - 1s 83us/step - loss: 0.1253 - acc: 0.9684 - val_loss: 0.1350 - val_acc: 0.9709\n",
      "Epoch 110/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1260 - acc: 0.9684 - val_loss: 0.1305 - val_acc: 0.9709\n",
      "Epoch 111/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1255 - acc: 0.9684 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 112/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1250 - acc: 0.9684 - val_loss: 0.1308 - val_acc: 0.9709\n",
      "Epoch 113/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1256 - acc: 0.9684 - val_loss: 0.1334 - val_acc: 0.9709\n",
      "Epoch 114/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1253 - acc: 0.9684 - val_loss: 0.1314 - val_acc: 0.9709\n",
      "Epoch 115/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1253 - acc: 0.9684 - val_loss: 0.1324 - val_acc: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1249 - acc: 0.9684 - val_loss: 0.1328 - val_acc: 0.9709\n",
      "Epoch 117/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1247 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 118/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1251 - acc: 0.9684 - val_loss: 0.1331 - val_acc: 0.9709\n",
      "Epoch 119/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1250 - acc: 0.9684 - val_loss: 0.1324 - val_acc: 0.9709\n",
      "Epoch 120/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1241 - acc: 0.9684 - val_loss: 0.1315 - val_acc: 0.9709\n",
      "Epoch 121/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 0.1340 - val_acc: 0.9709\n",
      "Epoch 122/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1243 - acc: 0.9684 - val_loss: 0.1328 - val_acc: 0.9709\n",
      "Epoch 123/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 0.1330 - val_acc: 0.9709\n",
      "Epoch 124/400\n",
      "16079/16079 [==============================] - 1s 56us/step - loss: 0.1248 - acc: 0.9684 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Epoch 125/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1243 - acc: 0.9684 - val_loss: 0.1330 - val_acc: 0.9709\n",
      "Epoch 126/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1244 - acc: 0.9684 - val_loss: 0.1339 - val_acc: 0.9709\n",
      "Epoch 127/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1240 - acc: 0.9684 - val_loss: 0.1360 - val_acc: 0.9709\n",
      "Epoch 128/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1242 - acc: 0.9684 - val_loss: 0.1388 - val_acc: 0.9709\n",
      "Epoch 129/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1242 - acc: 0.9684 - val_loss: 0.1321 - val_acc: 0.9709\n",
      "Epoch 130/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1245 - acc: 0.9684 - val_loss: 0.1337 - val_acc: 0.9709\n",
      "Epoch 131/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1240 - acc: 0.9684 - val_loss: 0.1336 - val_acc: 0.9709\n",
      "Epoch 132/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1240 - acc: 0.9684 - val_loss: 0.1346 - val_acc: 0.9709\n",
      "Epoch 133/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1241 - acc: 0.9685 - val_loss: 0.1333 - val_acc: 0.9709\n",
      "Epoch 134/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1239 - acc: 0.9685 - val_loss: 0.1328 - val_acc: 0.9709\n",
      "Epoch 135/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1233 - acc: 0.9684 - val_loss: 0.1344 - val_acc: 0.9709\n",
      "Epoch 136/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1240 - acc: 0.9685 - val_loss: 0.1354 - val_acc: 0.9709\n",
      "Epoch 137/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1240 - acc: 0.9685 - val_loss: 0.1347 - val_acc: 0.9709\n",
      "Epoch 138/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1233 - acc: 0.9685 - val_loss: 0.1363 - val_acc: 0.9709\n",
      "Epoch 139/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1236 - acc: 0.9685 - val_loss: 0.1351 - val_acc: 0.9709\n",
      "Epoch 140/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1235 - acc: 0.9685 - val_loss: 0.1338 - val_acc: 0.9709\n",
      "Epoch 141/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1235 - acc: 0.9684 - val_loss: 0.1395 - val_acc: 0.9709\n",
      "Epoch 142/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1232 - acc: 0.9685 - val_loss: 0.1333 - val_acc: 0.9709\n",
      "Epoch 143/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1232 - acc: 0.9685 - val_loss: 0.1359 - val_acc: 0.9709\n",
      "Epoch 144/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1233 - acc: 0.9685 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 145/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1233 - acc: 0.9685 - val_loss: 0.1340 - val_acc: 0.9709\n",
      "Epoch 146/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1231 - acc: 0.9685 - val_loss: 0.1352 - val_acc: 0.9709\n",
      "Epoch 147/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1231 - acc: 0.9685 - val_loss: 0.1351 - val_acc: 0.9709\n",
      "Epoch 148/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1228 - acc: 0.9686 - val_loss: 0.1348 - val_acc: 0.9709\n",
      "Epoch 149/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1232 - acc: 0.9685 - val_loss: 0.1350 - val_acc: 0.9709\n",
      "Epoch 150/400\n",
      "16079/16079 [==============================] - 1s 80us/step - loss: 0.1232 - acc: 0.9685 - val_loss: 0.1377 - val_acc: 0.9709\n",
      "Epoch 151/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1230 - acc: 0.9685 - val_loss: 0.1344 - val_acc: 0.9709\n",
      "Epoch 152/400\n",
      "16079/16079 [==============================] - 1s 55us/step - loss: 0.1231 - acc: 0.9686 - val_loss: 0.1320 - val_acc: 0.9709\n",
      "Epoch 153/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1237 - acc: 0.9684 - val_loss: 0.1366 - val_acc: 0.9709\n",
      "Epoch 154/400\n",
      "16079/16079 [==============================] - 1s 59us/step - loss: 0.1230 - acc: 0.9684 - val_loss: 0.1364 - val_acc: 0.9709\n",
      "Epoch 155/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1225 - acc: 0.9686 - val_loss: 0.1404 - val_acc: 0.9709\n",
      "Epoch 156/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1230 - acc: 0.9685 - val_loss: 0.1343 - val_acc: 0.9709\n",
      "Epoch 157/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1228 - acc: 0.9686 - val_loss: 0.1366 - val_acc: 0.9709\n",
      "Epoch 158/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1230 - acc: 0.9685 - val_loss: 0.1342 - val_acc: 0.9709\n",
      "Epoch 159/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1230 - acc: 0.9685 - val_loss: 0.1368 - val_acc: 0.9709\n",
      "Epoch 160/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1230 - acc: 0.9685 - val_loss: 0.1342 - val_acc: 0.9709\n",
      "Epoch 161/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1229 - acc: 0.9685 - val_loss: 0.1367 - val_acc: 0.9709\n",
      "Epoch 162/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1227 - acc: 0.9686 - val_loss: 0.1349 - val_acc: 0.9709\n",
      "Epoch 163/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1229 - acc: 0.9687 - val_loss: 0.1361 - val_acc: 0.9709\n",
      "Epoch 164/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1232 - acc: 0.9684 - val_loss: 0.1335 - val_acc: 0.9709\n",
      "Epoch 165/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1225 - acc: 0.9686 - val_loss: 0.1371 - val_acc: 0.9707\n",
      "Epoch 166/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1225 - acc: 0.9686 - val_loss: 0.1455 - val_acc: 0.9709\n",
      "Epoch 167/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1222 - acc: 0.9686 - val_loss: 0.1416 - val_acc: 0.9707\n",
      "Epoch 168/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1226 - acc: 0.9686 - val_loss: 0.1365 - val_acc: 0.9709\n",
      "Epoch 169/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1225 - acc: 0.9685 - val_loss: 0.1378 - val_acc: 0.9707\n",
      "Epoch 170/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1221 - acc: 0.9686 - val_loss: 0.1361 - val_acc: 0.9707\n",
      "Epoch 171/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1223 - acc: 0.9686 - val_loss: 0.1351 - val_acc: 0.9709\n",
      "Epoch 172/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1225 - acc: 0.9685 - val_loss: 0.1364 - val_acc: 0.9707\n",
      "Epoch 173/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1222 - acc: 0.9686 - val_loss: 0.1375 - val_acc: 0.9704\n",
      "Epoch 174/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1225 - acc: 0.9685 - val_loss: 0.1370 - val_acc: 0.9709\n",
      "Epoch 175/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1220 - acc: 0.9685 - val_loss: 0.1396 - val_acc: 0.9707\n",
      "Epoch 176/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1224 - acc: 0.9685 - val_loss: 0.1379 - val_acc: 0.9707\n",
      "Epoch 177/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1221 - acc: 0.9685 - val_loss: 0.1377 - val_acc: 0.9707\n",
      "Epoch 178/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1220 - acc: 0.9685 - val_loss: 0.1378 - val_acc: 0.9709\n",
      "Epoch 179/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1219 - acc: 0.9685 - val_loss: 0.1370 - val_acc: 0.9707\n",
      "Epoch 180/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1218 - acc: 0.9686 - val_loss: 0.1384 - val_acc: 0.9707\n",
      "Epoch 181/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1218 - acc: 0.9684 - val_loss: 0.1409 - val_acc: 0.9707\n",
      "Epoch 182/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1219 - acc: 0.9685 - val_loss: 0.1408 - val_acc: 0.9707\n",
      "Epoch 183/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1227 - acc: 0.9685 - val_loss: 0.1397 - val_acc: 0.9707\n",
      "Epoch 184/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1224 - acc: 0.9686 - val_loss: 0.1405 - val_acc: 0.9707\n",
      "Epoch 185/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1220 - acc: 0.9686 - val_loss: 0.1432 - val_acc: 0.9707\n",
      "Epoch 186/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1220 - acc: 0.9686 - val_loss: 0.1375 - val_acc: 0.9707\n",
      "Epoch 187/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1218 - acc: 0.9686 - val_loss: 0.1381 - val_acc: 0.9707\n",
      "Epoch 188/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1212 - acc: 0.9686 - val_loss: 0.1433 - val_acc: 0.9707\n",
      "Epoch 189/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1220 - acc: 0.9685 - val_loss: 0.1403 - val_acc: 0.9709\n",
      "Epoch 190/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1218 - acc: 0.9686 - val_loss: 0.1389 - val_acc: 0.9707\n",
      "Epoch 191/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1220 - acc: 0.9687 - val_loss: 0.1404 - val_acc: 0.9707\n",
      "Epoch 192/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1219 - acc: 0.9687 - val_loss: 0.1429 - val_acc: 0.9709\n",
      "Epoch 193/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1219 - acc: 0.9686 - val_loss: 0.1437 - val_acc: 0.9707\n",
      "Epoch 194/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1213 - acc: 0.9687 - val_loss: 0.1444 - val_acc: 0.9707\n",
      "Epoch 195/400\n",
      "16079/16079 [==============================] - 1s 82us/step - loss: 0.1218 - acc: 0.9685 - val_loss: 0.1388 - val_acc: 0.9707\n",
      "Epoch 196/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1213 - acc: 0.9686 - val_loss: 0.1537 - val_acc: 0.9707\n",
      "Epoch 197/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1218 - acc: 0.9686 - val_loss: 0.1413 - val_acc: 0.9707\n",
      "Epoch 198/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1212 - acc: 0.9687 - val_loss: 0.1408 - val_acc: 0.9709\n",
      "Epoch 199/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1217 - acc: 0.9685 - val_loss: 0.1416 - val_acc: 0.9707\n",
      "Epoch 200/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1212 - acc: 0.9686 - val_loss: 0.1391 - val_acc: 0.9707\n",
      "Epoch 201/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1211 - acc: 0.9687 - val_loss: 0.1390 - val_acc: 0.9707\n",
      "Epoch 202/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1208 - acc: 0.9686 - val_loss: 0.1483 - val_acc: 0.9707\n",
      "Epoch 203/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1211 - acc: 0.9687 - val_loss: 0.1401 - val_acc: 0.9709\n",
      "Epoch 204/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1210 - acc: 0.9686 - val_loss: 0.1439 - val_acc: 0.9707\n",
      "Epoch 205/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1210 - acc: 0.9687 - val_loss: 0.1401 - val_acc: 0.9709\n",
      "Epoch 206/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1219 - acc: 0.9684 - val_loss: 0.1430 - val_acc: 0.9707\n",
      "Epoch 207/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1210 - acc: 0.9687 - val_loss: 0.1411 - val_acc: 0.9704\n",
      "Epoch 208/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1213 - acc: 0.9686 - val_loss: 0.1430 - val_acc: 0.9707\n",
      "Epoch 209/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1207 - acc: 0.9686 - val_loss: 0.1388 - val_acc: 0.9707\n",
      "Epoch 210/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1209 - acc: 0.9684 - val_loss: 0.1392 - val_acc: 0.9704\n",
      "Epoch 211/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1212 - acc: 0.9686 - val_loss: 0.1418 - val_acc: 0.9704\n",
      "Epoch 212/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1208 - acc: 0.9686 - val_loss: 0.1388 - val_acc: 0.9707\n",
      "Epoch 213/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1209 - acc: 0.9685 - val_loss: 0.1472 - val_acc: 0.9707\n",
      "Epoch 214/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1207 - acc: 0.9686 - val_loss: 0.1479 - val_acc: 0.9709\n",
      "Epoch 215/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1205 - acc: 0.9687 - val_loss: 0.1451 - val_acc: 0.9707\n",
      "Epoch 216/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1211 - acc: 0.9686 - val_loss: 0.1407 - val_acc: 0.9707\n",
      "Epoch 217/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1206 - acc: 0.9687 - val_loss: 0.1488 - val_acc: 0.9707\n",
      "Epoch 218/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1202 - acc: 0.9686 - val_loss: 0.1541 - val_acc: 0.9707\n",
      "Epoch 219/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1205 - acc: 0.9686 - val_loss: 0.1425 - val_acc: 0.9707\n",
      "Epoch 220/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1203 - acc: 0.9687 - val_loss: 0.1410 - val_acc: 0.9707\n",
      "Epoch 221/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1205 - acc: 0.9687 - val_loss: 0.1385 - val_acc: 0.9707\n",
      "Epoch 222/400\n",
      "16079/16079 [==============================] - 1s 84us/step - loss: 0.1208 - acc: 0.9685 - val_loss: 0.1431 - val_acc: 0.9707\n",
      "Epoch 223/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1204 - acc: 0.9686 - val_loss: 0.1415 - val_acc: 0.9707\n",
      "Epoch 224/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1207 - acc: 0.9687 - val_loss: 0.1416 - val_acc: 0.9707\n",
      "Epoch 225/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1207 - acc: 0.9686 - val_loss: 0.1458 - val_acc: 0.9707\n",
      "Epoch 226/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1202 - acc: 0.9688 - val_loss: 0.1436 - val_acc: 0.9707\n",
      "Epoch 227/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1204 - acc: 0.9686 - val_loss: 0.1424 - val_acc: 0.9707\n",
      "Epoch 228/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1202 - acc: 0.9686 - val_loss: 0.1448 - val_acc: 0.9707\n",
      "Epoch 229/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1199 - acc: 0.9686 - val_loss: 0.1494 - val_acc: 0.9704\n",
      "Epoch 230/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1201 - acc: 0.9687 - val_loss: 0.1437 - val_acc: 0.9707\n",
      "Epoch 231/400\n",
      "16079/16079 [==============================] - 1s 82us/step - loss: 0.1211 - acc: 0.9687 - val_loss: 0.1386 - val_acc: 0.9707\n",
      "Epoch 232/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1199 - acc: 0.9687 - val_loss: 0.1451 - val_acc: 0.9707\n",
      "Epoch 233/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1197 - acc: 0.9687 - val_loss: 0.1424 - val_acc: 0.9707\n",
      "Epoch 234/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1201 - acc: 0.9687 - val_loss: 0.1470 - val_acc: 0.9707\n",
      "Epoch 235/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1201 - acc: 0.9687 - val_loss: 0.1399 - val_acc: 0.9704\n",
      "Epoch 236/400\n",
      "16079/16079 [==============================] - 1s 57us/step - loss: 0.1206 - acc: 0.9685 - val_loss: 0.1416 - val_acc: 0.9707\n",
      "Epoch 237/400\n",
      "16079/16079 [==============================] - 1s 60us/step - loss: 0.1200 - acc: 0.9686 - val_loss: 0.1437 - val_acc: 0.9704\n",
      "Epoch 238/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1195 - acc: 0.9686 - val_loss: 0.1470 - val_acc: 0.9707\n",
      "Epoch 239/400\n",
      "16079/16079 [==============================] - 1s 59us/step - loss: 0.1196 - acc: 0.9687 - val_loss: 0.1448 - val_acc: 0.9707\n",
      "Epoch 240/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1199 - acc: 0.9687 - val_loss: 0.1449 - val_acc: 0.9707\n",
      "Epoch 241/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1205 - acc: 0.9687 - val_loss: 0.1453 - val_acc: 0.9707\n",
      "Epoch 242/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1197 - acc: 0.9686 - val_loss: 0.1415 - val_acc: 0.9707\n",
      "Epoch 243/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1194 - acc: 0.9686 - val_loss: 0.1443 - val_acc: 0.9707\n",
      "Epoch 244/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1196 - acc: 0.9686 - val_loss: 0.1444 - val_acc: 0.9707\n",
      "Epoch 245/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1193 - acc: 0.9685 - val_loss: 0.1476 - val_acc: 0.9707\n",
      "Epoch 246/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1199 - acc: 0.9686 - val_loss: 0.1484 - val_acc: 0.9707\n",
      "Epoch 247/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1200 - acc: 0.9685 - val_loss: 0.1456 - val_acc: 0.9707\n",
      "Epoch 248/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1196 - acc: 0.9687 - val_loss: 0.1418 - val_acc: 0.9707\n",
      "Epoch 249/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1193 - acc: 0.9685 - val_loss: 0.1442 - val_acc: 0.9707\n",
      "Epoch 250/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1194 - acc: 0.9687 - val_loss: 0.1455 - val_acc: 0.9707\n",
      "Epoch 251/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1197 - acc: 0.9687 - val_loss: 0.1494 - val_acc: 0.9704\n",
      "Epoch 252/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1191 - acc: 0.9687 - val_loss: 0.1428 - val_acc: 0.9707\n",
      "Epoch 253/400\n",
      "16079/16079 [==============================] - 1s 83us/step - loss: 0.1196 - acc: 0.9686 - val_loss: 0.1456 - val_acc: 0.9707\n",
      "Epoch 254/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1192 - acc: 0.9686 - val_loss: 0.1453 - val_acc: 0.9707\n",
      "Epoch 255/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1196 - acc: 0.9687 - val_loss: 0.1464 - val_acc: 0.9707\n",
      "Epoch 256/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1194 - acc: 0.9687 - val_loss: 0.1435 - val_acc: 0.9707\n",
      "Epoch 257/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1192 - acc: 0.9687 - val_loss: 0.1444 - val_acc: 0.9707\n",
      "Epoch 258/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1193 - acc: 0.9687 - val_loss: 0.1448 - val_acc: 0.9707\n",
      "Epoch 259/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1195 - acc: 0.9687 - val_loss: 0.1466 - val_acc: 0.9707\n",
      "Epoch 260/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1188 - acc: 0.9687 - val_loss: 0.1484 - val_acc: 0.9707\n",
      "Epoch 261/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1196 - acc: 0.9686 - val_loss: 0.1491 - val_acc: 0.9704\n",
      "Epoch 262/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1194 - acc: 0.9686 - val_loss: 0.1493 - val_acc: 0.9707\n",
      "Epoch 263/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1187 - acc: 0.9687 - val_loss: 0.1503 - val_acc: 0.9707\n",
      "Epoch 264/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1187 - acc: 0.9687 - val_loss: 0.1462 - val_acc: 0.9707\n",
      "Epoch 265/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1193 - acc: 0.9687 - val_loss: 0.1472 - val_acc: 0.9707\n",
      "Epoch 266/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1187 - acc: 0.9687 - val_loss: 0.1439 - val_acc: 0.9707\n",
      "Epoch 267/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1196 - acc: 0.9687 - val_loss: 0.1495 - val_acc: 0.9707\n",
      "Epoch 268/400\n",
      "16079/16079 [==============================] - 1s 54us/step - loss: 0.1190 - acc: 0.9687 - val_loss: 0.1504 - val_acc: 0.9707\n",
      "Epoch 269/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1184 - acc: 0.9687 - val_loss: 0.1438 - val_acc: 0.9707\n",
      "Epoch 270/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1186 - acc: 0.9687 - val_loss: 0.1470 - val_acc: 0.9704\n",
      "Epoch 271/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1185 - acc: 0.9687 - val_loss: 0.1458 - val_acc: 0.9707\n",
      "Epoch 272/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1188 - acc: 0.9686 - val_loss: 0.1447 - val_acc: 0.9707\n",
      "Epoch 273/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1183 - acc: 0.9687 - val_loss: 0.1467 - val_acc: 0.9707\n",
      "Epoch 274/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1183 - acc: 0.9687 - val_loss: 0.1463 - val_acc: 0.9707\n",
      "Epoch 275/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1182 - acc: 0.9687 - val_loss: 0.1489 - val_acc: 0.9707\n",
      "Epoch 276/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1182 - acc: 0.9687 - val_loss: 0.1486 - val_acc: 0.9704\n",
      "Epoch 277/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1183 - acc: 0.9688 - val_loss: 0.1476 - val_acc: 0.9707\n",
      "Epoch 278/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1180 - acc: 0.9688 - val_loss: 0.1481 - val_acc: 0.9702\n",
      "Epoch 279/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1186 - acc: 0.9687 - val_loss: 0.1475 - val_acc: 0.9707\n",
      "Epoch 280/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1181 - acc: 0.9687 - val_loss: 0.1446 - val_acc: 0.9707\n",
      "Epoch 281/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1179 - acc: 0.9687 - val_loss: 0.1544 - val_acc: 0.9704\n",
      "Epoch 282/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1182 - acc: 0.9687 - val_loss: 0.1481 - val_acc: 0.9707\n",
      "Epoch 283/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1182 - acc: 0.9686 - val_loss: 0.1594 - val_acc: 0.9702\n",
      "Epoch 284/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1175 - acc: 0.9687 - val_loss: 0.1511 - val_acc: 0.9707\n",
      "Epoch 285/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1182 - acc: 0.9687 - val_loss: 0.1505 - val_acc: 0.9704\n",
      "Epoch 286/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1179 - acc: 0.9687 - val_loss: 0.1453 - val_acc: 0.9707\n",
      "Epoch 287/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1180 - acc: 0.9688 - val_loss: 0.1464 - val_acc: 0.9704\n",
      "Epoch 288/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1180 - acc: 0.9688 - val_loss: 0.1534 - val_acc: 0.9707\n",
      "Epoch 289/400\n",
      "16079/16079 [==============================] - 1s 84us/step - loss: 0.1180 - acc: 0.9686 - val_loss: 0.1452 - val_acc: 0.9707\n",
      "Epoch 290/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1176 - acc: 0.9688 - val_loss: 0.1518 - val_acc: 0.9704\n",
      "Epoch 291/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1180 - acc: 0.9688 - val_loss: 0.1519 - val_acc: 0.9707\n",
      "Epoch 292/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1178 - acc: 0.9687 - val_loss: 0.1463 - val_acc: 0.9702\n",
      "Epoch 293/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1176 - acc: 0.9688 - val_loss: 0.1495 - val_acc: 0.9707\n",
      "Epoch 294/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1176 - acc: 0.9687 - val_loss: 0.1547 - val_acc: 0.9704\n",
      "Epoch 295/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1177 - acc: 0.9687 - val_loss: 0.1555 - val_acc: 0.9707\n",
      "Epoch 296/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1173 - acc: 0.9688 - val_loss: 0.1480 - val_acc: 0.9697\n",
      "Epoch 297/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1176 - acc: 0.9687 - val_loss: 0.1596 - val_acc: 0.9704\n",
      "Epoch 298/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1175 - acc: 0.9688 - val_loss: 0.1543 - val_acc: 0.9702\n",
      "Epoch 299/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1181 - acc: 0.9687 - val_loss: 0.1460 - val_acc: 0.9704\n",
      "Epoch 300/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1173 - acc: 0.9687 - val_loss: 0.1490 - val_acc: 0.9702\n",
      "Epoch 301/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1174 - acc: 0.9687 - val_loss: 0.1531 - val_acc: 0.9704\n",
      "Epoch 302/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1177 - acc: 0.9687 - val_loss: 0.1504 - val_acc: 0.9707\n",
      "Epoch 303/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1174 - acc: 0.9688 - val_loss: 0.1625 - val_acc: 0.9707\n",
      "Epoch 304/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1171 - acc: 0.9687 - val_loss: 0.1576 - val_acc: 0.9707\n",
      "Epoch 305/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1176 - acc: 0.9687 - val_loss: 0.1457 - val_acc: 0.9704\n",
      "Epoch 306/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1175 - acc: 0.9687 - val_loss: 0.1500 - val_acc: 0.9704\n",
      "Epoch 307/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1167 - acc: 0.9688 - val_loss: 0.1489 - val_acc: 0.9702\n",
      "Epoch 308/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1172 - acc: 0.9686 - val_loss: 0.1558 - val_acc: 0.9702\n",
      "Epoch 309/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1173 - acc: 0.9688 - val_loss: 0.1561 - val_acc: 0.9707\n",
      "Epoch 310/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1169 - acc: 0.9687 - val_loss: 0.1450 - val_acc: 0.9704\n",
      "Epoch 311/400\n",
      "16079/16079 [==============================] - 1s 85us/step - loss: 0.1176 - acc: 0.9687 - val_loss: 0.1521 - val_acc: 0.9707\n",
      "Epoch 312/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1172 - acc: 0.9687 - val_loss: 0.1590 - val_acc: 0.9702\n",
      "Epoch 313/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1171 - acc: 0.9688 - val_loss: 0.1515 - val_acc: 0.9697\n",
      "Epoch 314/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1175 - acc: 0.9686 - val_loss: 0.1449 - val_acc: 0.9704\n",
      "Epoch 315/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1165 - acc: 0.9688 - val_loss: 0.1476 - val_acc: 0.9702\n",
      "Epoch 316/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1162 - acc: 0.9688 - val_loss: 0.1541 - val_acc: 0.9697\n",
      "Epoch 317/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1169 - acc: 0.9688 - val_loss: 0.1551 - val_acc: 0.9707\n",
      "Epoch 318/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1172 - acc: 0.9688 - val_loss: 0.1602 - val_acc: 0.9704\n",
      "Epoch 319/400\n",
      "16079/16079 [==============================] - 1s 57us/step - loss: 0.1174 - acc: 0.9687 - val_loss: 0.1510 - val_acc: 0.9699\n",
      "Epoch 320/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1171 - acc: 0.9686 - val_loss: 0.1481 - val_acc: 0.9699\n",
      "Epoch 321/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1161 - acc: 0.9690 - val_loss: 0.1578 - val_acc: 0.9707\n",
      "Epoch 322/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1176 - acc: 0.9685 - val_loss: 0.1658 - val_acc: 0.9704\n",
      "Epoch 323/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1175 - acc: 0.9687 - val_loss: 0.1593 - val_acc: 0.9702\n",
      "Epoch 324/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1167 - acc: 0.9689 - val_loss: 0.1500 - val_acc: 0.9707\n",
      "Epoch 325/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1160 - acc: 0.9687 - val_loss: 0.1514 - val_acc: 0.9702\n",
      "Epoch 326/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1155 - acc: 0.9689 - val_loss: 0.1635 - val_acc: 0.9704\n",
      "Epoch 327/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1166 - acc: 0.9686 - val_loss: 0.1536 - val_acc: 0.9697\n",
      "Epoch 328/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1158 - acc: 0.9685 - val_loss: 0.1533 - val_acc: 0.9704\n",
      "Epoch 329/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1160 - acc: 0.9688 - val_loss: 0.1558 - val_acc: 0.9697\n",
      "Epoch 330/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1156 - acc: 0.9688 - val_loss: 0.1530 - val_acc: 0.9707\n",
      "Epoch 331/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1160 - acc: 0.9689 - val_loss: 0.1571 - val_acc: 0.9687\n",
      "Epoch 332/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1168 - acc: 0.9688 - val_loss: 0.1472 - val_acc: 0.9702\n",
      "Epoch 333/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1158 - acc: 0.9688 - val_loss: 0.1532 - val_acc: 0.9702\n",
      "Epoch 334/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1166 - acc: 0.9687 - val_loss: 0.1513 - val_acc: 0.9702\n",
      "Epoch 335/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1162 - acc: 0.9687 - val_loss: 0.1503 - val_acc: 0.9699\n",
      "Epoch 336/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1154 - acc: 0.9688 - val_loss: 0.1583 - val_acc: 0.9707\n",
      "Epoch 337/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1160 - acc: 0.9687 - val_loss: 0.1528 - val_acc: 0.9704\n",
      "Epoch 338/400\n",
      "16079/16079 [==============================] - 1s 84us/step - loss: 0.1164 - acc: 0.9686 - val_loss: 0.1510 - val_acc: 0.9697\n",
      "Epoch 339/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1154 - acc: 0.9687 - val_loss: 0.1532 - val_acc: 0.9707\n",
      "Epoch 340/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1156 - acc: 0.9688 - val_loss: 0.1525 - val_acc: 0.9702\n",
      "Epoch 341/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1154 - acc: 0.9687 - val_loss: 0.1562 - val_acc: 0.9697\n",
      "Epoch 342/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1167 - acc: 0.9687 - val_loss: 0.1473 - val_acc: 0.9702\n",
      "Epoch 343/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1160 - acc: 0.9690 - val_loss: 0.1499 - val_acc: 0.9704\n",
      "Epoch 344/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1157 - acc: 0.9687 - val_loss: 0.1622 - val_acc: 0.9699\n",
      "Epoch 345/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1162 - acc: 0.9690 - val_loss: 0.1473 - val_acc: 0.9699\n",
      "Epoch 346/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1153 - acc: 0.9687 - val_loss: 0.1565 - val_acc: 0.9697\n",
      "Epoch 347/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1148 - acc: 0.9687 - val_loss: 0.1679 - val_acc: 0.9689\n",
      "Epoch 348/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1161 - acc: 0.9687 - val_loss: 0.1493 - val_acc: 0.9699\n",
      "Epoch 349/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1158 - acc: 0.9690 - val_loss: 0.1501 - val_acc: 0.9699\n",
      "Epoch 350/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1161 - acc: 0.9688 - val_loss: 0.1559 - val_acc: 0.9699\n",
      "Epoch 351/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1145 - acc: 0.9690 - val_loss: 0.1559 - val_acc: 0.9697\n",
      "Epoch 352/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1157 - acc: 0.9687 - val_loss: 0.1587 - val_acc: 0.9697\n",
      "Epoch 353/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1167 - acc: 0.9688 - val_loss: 0.1560 - val_acc: 0.9704\n",
      "Epoch 354/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1158 - acc: 0.9687 - val_loss: 0.1572 - val_acc: 0.9702\n",
      "Epoch 355/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1152 - acc: 0.9687 - val_loss: 0.1540 - val_acc: 0.9702\n",
      "Epoch 356/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1162 - acc: 0.9688 - val_loss: 0.1500 - val_acc: 0.9704\n",
      "Epoch 357/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1154 - acc: 0.9687 - val_loss: 0.1634 - val_acc: 0.9702\n",
      "Epoch 358/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1148 - acc: 0.9688 - val_loss: 0.1571 - val_acc: 0.9704\n",
      "Epoch 359/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1145 - acc: 0.9689 - val_loss: 0.1563 - val_acc: 0.9697\n",
      "Epoch 360/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1150 - acc: 0.9688 - val_loss: 0.1515 - val_acc: 0.9702\n",
      "Epoch 361/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1151 - acc: 0.9688 - val_loss: 0.1543 - val_acc: 0.9697\n",
      "Epoch 362/400\n",
      "16079/16079 [==============================] - 1s 69us/step - loss: 0.1157 - acc: 0.9689 - val_loss: 0.1521 - val_acc: 0.9697\n",
      "Epoch 363/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1152 - acc: 0.9687 - val_loss: 0.1522 - val_acc: 0.9697\n",
      "Epoch 364/400\n",
      "16079/16079 [==============================] - 1s 82us/step - loss: 0.1145 - acc: 0.9688 - val_loss: 0.1559 - val_acc: 0.9699\n",
      "Epoch 365/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1151 - acc: 0.9688 - val_loss: 0.1567 - val_acc: 0.9704\n",
      "Epoch 366/400\n",
      "16079/16079 [==============================] - 1s 55us/step - loss: 0.1149 - acc: 0.9687 - val_loss: 0.1606 - val_acc: 0.9699\n",
      "Epoch 367/400\n",
      "16079/16079 [==============================] - 1s 62us/step - loss: 0.1152 - acc: 0.9688 - val_loss: 0.1530 - val_acc: 0.9699\n",
      "Epoch 368/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1147 - acc: 0.9689 - val_loss: 0.1670 - val_acc: 0.9702\n",
      "Epoch 369/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1144 - acc: 0.9687 - val_loss: 0.1652 - val_acc: 0.9702\n",
      "Epoch 370/400\n",
      "16079/16079 [==============================] - 1s 55us/step - loss: 0.1150 - acc: 0.9689 - val_loss: 0.1552 - val_acc: 0.9699\n",
      "Epoch 371/400\n",
      "16079/16079 [==============================] - 1s 58us/step - loss: 0.1152 - acc: 0.9690 - val_loss: 0.1540 - val_acc: 0.9699\n",
      "Epoch 372/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1143 - acc: 0.9688 - val_loss: 0.1574 - val_acc: 0.9704\n",
      "Epoch 373/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1145 - acc: 0.9689 - val_loss: 0.1682 - val_acc: 0.9697\n",
      "Epoch 374/400\n",
      "16079/16079 [==============================] - 1s 74us/step - loss: 0.1140 - acc: 0.9690 - val_loss: 0.1602 - val_acc: 0.9704\n",
      "Epoch 375/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1150 - acc: 0.9690 - val_loss: 0.1610 - val_acc: 0.9697\n",
      "Epoch 376/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1146 - acc: 0.9686 - val_loss: 0.1606 - val_acc: 0.9697\n",
      "Epoch 377/400\n",
      "16079/16079 [==============================] - 1s 61us/step - loss: 0.1145 - acc: 0.9688 - val_loss: 0.1493 - val_acc: 0.9699\n",
      "Epoch 378/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1142 - acc: 0.9691 - val_loss: 0.1766 - val_acc: 0.9704\n",
      "Epoch 379/400\n",
      "16079/16079 [==============================] - 1s 78us/step - loss: 0.1146 - acc: 0.9690 - val_loss: 0.1622 - val_acc: 0.9699\n",
      "Epoch 380/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1146 - acc: 0.9690 - val_loss: 0.1525 - val_acc: 0.9702\n",
      "Epoch 381/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1151 - acc: 0.9689 - val_loss: 0.1579 - val_acc: 0.9702\n",
      "Epoch 382/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1142 - acc: 0.9688 - val_loss: 0.1554 - val_acc: 0.9697\n",
      "Epoch 383/400\n",
      "16079/16079 [==============================] - 1s 68us/step - loss: 0.1135 - acc: 0.9689 - val_loss: 0.1633 - val_acc: 0.9702\n",
      "Epoch 384/400\n",
      "16079/16079 [==============================] - 1s 75us/step - loss: 0.1149 - acc: 0.9688 - val_loss: 0.1577 - val_acc: 0.9702\n",
      "Epoch 385/400\n",
      "16079/16079 [==============================] - 1s 72us/step - loss: 0.1158 - acc: 0.9689 - val_loss: 0.1564 - val_acc: 0.9702\n",
      "Epoch 386/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1145 - acc: 0.9689 - val_loss: 0.1592 - val_acc: 0.9699\n",
      "Epoch 387/400\n",
      "16079/16079 [==============================] - 1s 67us/step - loss: 0.1139 - acc: 0.9690 - val_loss: 0.1577 - val_acc: 0.9697\n",
      "Epoch 388/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1150 - acc: 0.9688 - val_loss: 0.1623 - val_acc: 0.9692\n",
      "Epoch 389/400\n",
      "16079/16079 [==============================] - 1s 64us/step - loss: 0.1148 - acc: 0.9688 - val_loss: 0.1555 - val_acc: 0.9702\n",
      "Epoch 390/400\n",
      "16079/16079 [==============================] - 1s 65us/step - loss: 0.1134 - acc: 0.9688 - val_loss: 0.1648 - val_acc: 0.9697\n",
      "Epoch 391/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1134 - acc: 0.9689 - val_loss: 0.1596 - val_acc: 0.9697\n",
      "Epoch 392/400\n",
      "16079/16079 [==============================] - 1s 76us/step - loss: 0.1138 - acc: 0.9687 - val_loss: 0.1673 - val_acc: 0.9697\n",
      "Epoch 393/400\n",
      "16079/16079 [==============================] - 1s 70us/step - loss: 0.1135 - acc: 0.9690 - val_loss: 0.1612 - val_acc: 0.9699\n",
      "Epoch 394/400\n",
      "16079/16079 [==============================] - 1s 71us/step - loss: 0.1145 - acc: 0.9689 - val_loss: 0.1596 - val_acc: 0.9702\n",
      "Epoch 395/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1134 - acc: 0.9689 - val_loss: 0.1595 - val_acc: 0.9699\n",
      "Epoch 396/400\n",
      "16079/16079 [==============================] - 1s 63us/step - loss: 0.1148 - acc: 0.9687 - val_loss: 0.1559 - val_acc: 0.9699\n",
      "Epoch 397/400\n",
      "16079/16079 [==============================] - 1s 79us/step - loss: 0.1135 - acc: 0.9689 - val_loss: 0.1591 - val_acc: 0.9694\n",
      "Epoch 398/400\n",
      "16079/16079 [==============================] - 1s 73us/step - loss: 0.1139 - acc: 0.9688 - val_loss: 0.1633 - val_acc: 0.9699\n",
      "Epoch 399/400\n",
      "16079/16079 [==============================] - 1s 66us/step - loss: 0.1136 - acc: 0.9688 - val_loss: 0.1605 - val_acc: 0.9702\n",
      "Epoch 400/400\n",
      "16079/16079 [==============================] - 1s 77us/step - loss: 0.1144 - acc: 0.9688 - val_loss: 0.1570 - val_acc: 0.9694\n",
      "463.1787929534912  seconds\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "# Takes about 5230.725239038467  seconds About 1 and 1/2 hours for 1000 epochs\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    # train_X_no_vectors, \n",
    "    train_y, \n",
    "    epochs=400,\n",
    "    # validation_split=0.4\n",
    "    validation_data=(validation_X, validation_y)\n",
    "    \n",
    ")\n",
    "end = time.time()\n",
    "print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history.history['loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/akashsri99/deep-learning-iris-dataset-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predictions = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.2734563e-01, 7.2654426e-02],\n",
       "       [1.0000000e+00, 8.1595126e-33],\n",
       "       [1.0000000e+00, 1.0054267e-17],\n",
       "       [1.0000000e+00, 3.1066625e-22],\n",
       "       [9.9933606e-01, 6.6390319e-04],\n",
       "       [1.0000000e+00, 1.0092078e-17],\n",
       "       [1.0000000e+00, 8.1388003e-35],\n",
       "       [1.0000000e+00, 1.6771973e-15],\n",
       "       [1.0000000e+00, 6.1175647e-09],\n",
       "       [9.5507628e-01, 4.4923704e-02]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = np.argmax(test_y,axis=1)\n",
    "y_pred_class = np.argmax(test_y_predictions,axis=1)\n",
    "\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(648,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_test_class.shape == y_pred_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classification problem\n",
    "https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/\n",
    "This happens because Machine Learning Algorithms are usually designed to improve accuracy by reducing the error. Thus, they do not take into account the class distribution / proportion or balance of classes.\n",
    "\n",
    "[A Review of Class Imbalance Problem (Shaza M. Abd Elrahman and Ajith Abraham)](http://ias04.softcomputing.net/jnic2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       619\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       648\n",
      "   macro avg       0.48      0.50      0.49       648\n",
      "weighted avg       0.91      0.95      0.93       648\n",
      "\n",
      "[[618   1]\n",
      " [ 29   0]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Recurrent Neural Network Instead\n",
    "It seems that adding sentence vectors as windows around the sentence does not work well with a feed forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "218\n",
      "(25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 2,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 2,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 2,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(X_train[0]))\n",
    "print(X_test.shape)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       [ 687,   23,    4, ...,   21,   64, 2574],\n",
       "       [   0,    0,    0, ...,    7,   61,  113]], dtype=int32)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    1,  591,  202,   14,   31,    6,  717,   10,\n",
       "         10,    2,    2,    5,    4,  360,    7,    4,  177,    2,  394,\n",
       "        354,    4,  123,    9, 1035, 1035, 1035,   10,   10,   13,   92,\n",
       "        124,   89,  488,    2,  100,   28, 1668,   14,   31,   23,   27,\n",
       "          2,   29,  220,  468,    8,  124,   14,  286,  170,    8,  157,\n",
       "         46,    5,   27,  239,   16,  179,    2,   38,   32,   25,    2,\n",
       "        451,  202,   14,    6,  717], dtype=int32)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "imdb_model = Sequential()\n",
    "imdb_model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "imdb_model.add(LSTM(100))\n",
    "imdb_model.add(Dense(1, activation='sigmoid'))\n",
    "imdb_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(imdb_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 204s 8ms/step - loss: 0.5887 - acc: 0.6728 - val_loss: 0.5178 - val_acc: 0.7478\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 193s 8ms/step - loss: 0.3717 - acc: 0.8384 - val_loss: 0.3916 - val_acc: 0.8476\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 195s 8ms/step - loss: 0.2686 - acc: 0.8935 - val_loss: 0.3383 - val_acc: 0.8628\n"
     ]
    }
   ],
   "source": [
    "imdb_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_loss_values = imdb_history.history['loss']\n",
    "imdb_epochs = range(1, len(imdb_loss_values)+1)\n",
    "\n",
    "plt.plot(imdb_epochs, imdb_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079, 156)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.788992</td>\n",
       "      <td>8.923999e-08</td>\n",
       "      <td>-7.957217e-09</td>\n",
       "      <td>-5.274117e-09</td>\n",
       "      <td>-1.910836e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.032557e-08</td>\n",
       "      <td>4.709798e-09</td>\n",
       "      <td>-7.814833e-08</td>\n",
       "      <td>3.333242e-08</td>\n",
       "      <td>-1.757239e-08</td>\n",
       "      <td>-4.967683e-09</td>\n",
       "      <td>3.275183e-08</td>\n",
       "      <td>-4.288362e-08</td>\n",
       "      <td>2.537755e-09</td>\n",
       "      <td>2.285525e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026734</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>1.138727e-09</td>\n",
       "      <td>-1.818176e-08</td>\n",
       "      <td>4.798956e-09</td>\n",
       "      <td>-5.157600e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.880125e-08</td>\n",
       "      <td>-1.505285e-08</td>\n",
       "      <td>-3.228048e-08</td>\n",
       "      <td>6.559005e-08</td>\n",
       "      <td>2.989873e-08</td>\n",
       "      <td>-2.563377e-08</td>\n",
       "      <td>-3.230809e-08</td>\n",
       "      <td>-1.410832e-08</td>\n",
       "      <td>3.297067e-08</td>\n",
       "      <td>8.902228e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.051728</td>\n",
       "      <td>-4.177528e-09</td>\n",
       "      <td>-1.188295e-08</td>\n",
       "      <td>2.389462e-08</td>\n",
       "      <td>-1.349990e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.331976e-08</td>\n",
       "      <td>-2.124629e-08</td>\n",
       "      <td>-5.314322e-09</td>\n",
       "      <td>4.871865e-08</td>\n",
       "      <td>2.572267e-08</td>\n",
       "      <td>-1.130713e-08</td>\n",
       "      <td>-3.515117e-08</td>\n",
       "      <td>2.479115e-08</td>\n",
       "      <td>9.735289e-09</td>\n",
       "      <td>3.229467e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.027952</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>-2.529559e-09</td>\n",
       "      <td>-1.465508e-08</td>\n",
       "      <td>8.994467e-09</td>\n",
       "      <td>8.784771e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564207e-08</td>\n",
       "      <td>1.737575e-09</td>\n",
       "      <td>2.070995e-08</td>\n",
       "      <td>-6.362434e-10</td>\n",
       "      <td>-2.201059e-08</td>\n",
       "      <td>2.865113e-08</td>\n",
       "      <td>-7.716492e-09</td>\n",
       "      <td>-3.310467e-08</td>\n",
       "      <td>-9.572791e-09</td>\n",
       "      <td>-1.052344e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.084493</td>\n",
       "      <td>-2.828828e-10</td>\n",
       "      <td>4.331747e-10</td>\n",
       "      <td>8.529943e-11</td>\n",
       "      <td>-2.281351e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.957617e-11</td>\n",
       "      <td>-1.465501e-10</td>\n",
       "      <td>1.223374e-10</td>\n",
       "      <td>1.708342e-10</td>\n",
       "      <td>3.674844e-10</td>\n",
       "      <td>1.448876e-10</td>\n",
       "      <td>6.751768e-10</td>\n",
       "      <td>1.813555e-10</td>\n",
       "      <td>6.316711e-10</td>\n",
       "      <td>-4.996572e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "0                    0.000436         0.013699                      0.0   \n",
       "1                    0.000871         0.178082                      0.0   \n",
       "2                    0.001307         0.136986                      0.0   \n",
       "3                    0.001743         0.068493                      0.0   \n",
       "4                    0.002179         0.109589                      0.0   \n",
       "\n",
       "   sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \\\n",
       "0           0.6249                0.006050                0.788992   \n",
       "1           0.0000                0.026734                0.042729   \n",
       "2           0.0000                0.031086                0.051728   \n",
       "3           0.0000                0.027952                0.142905   \n",
       "4           0.2263                0.017715                0.084493   \n",
       "\n",
       "              1             2             3             4  ...           141  \\\n",
       "0  8.923999e-08 -7.957217e-09 -5.274117e-09 -1.910836e-08  ...  5.032557e-08   \n",
       "1  1.138727e-09 -1.818176e-08  4.798956e-09 -5.157600e-08  ...  3.880125e-08   \n",
       "2 -4.177528e-09 -1.188295e-08  2.389462e-08 -1.349990e-08  ...  2.331976e-08   \n",
       "3 -2.529559e-09 -1.465508e-08  8.994467e-09  8.784771e-09  ...  2.564207e-08   \n",
       "4 -2.828828e-10  4.331747e-10  8.529943e-11 -2.281351e-10  ...  2.957617e-11   \n",
       "\n",
       "            142           143           144           145           146  \\\n",
       "0  4.709798e-09 -7.814833e-08  3.333242e-08 -1.757239e-08 -4.967683e-09   \n",
       "1 -1.505285e-08 -3.228048e-08  6.559005e-08  2.989873e-08 -2.563377e-08   \n",
       "2 -2.124629e-08 -5.314322e-09  4.871865e-08  2.572267e-08 -1.130713e-08   \n",
       "3  1.737575e-09  2.070995e-08 -6.362434e-10 -2.201059e-08  2.865113e-08   \n",
       "4 -1.465501e-10  1.223374e-10  1.708342e-10  3.674844e-10  1.448876e-10   \n",
       "\n",
       "            147           148           149           150  \n",
       "0  3.275183e-08 -4.288362e-08  2.537755e-09  2.285525e-08  \n",
       "1 -3.230809e-08 -1.410832e-08  3.297067e-08  8.902228e-08  \n",
       "2 -3.515117e-08  2.479115e-08  9.735289e-09  3.229467e-08  \n",
       "3 -7.716492e-09 -3.310467e-08 -9.572791e-09 -1.052344e-08  \n",
       "4  6.751768e-10  1.813555e-10  6.316711e-10 -4.996572e-10  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A many to many RNN\n",
    "#get number of columns in training data\n",
    "embedding_vector_length = 32\n",
    "num_of_cols = train_vectors_df.shape[1]\n",
    "rnn_model = Sequential()\n",
    "# rnn_model.add(Dense(num_of_cols, activation='relu', input_shape=(num_of_cols, 1)))\n",
    "rnn_model.add(Embedding(train_vectors_df.shape[0], embedding_vector_length, input_length=num_of_cols))\n",
    "rnn_model.add(Dropout(0.2))\n",
    "rnn_model.add(LSTM(100))\n",
    "rnn_model.add(Dropout(0.2))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 150, 32)           514528    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 150, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 567,829\n",
      "Trainable params: 567,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16079 samples, validate on 3988 samples\n",
      "Epoch 1/10\n",
      "16079/16079 [==============================] - 35s 2ms/step - loss: 0.1416 - acc: 0.9684 - val_loss: 0.1325 - val_acc: 0.9709\n",
      "Epoch 2/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1414 - acc: 0.9684 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "Epoch 3/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1413 - acc: 0.9684 - val_loss: 0.1333 - val_acc: 0.9709\n",
      "Epoch 4/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1415 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 5/10\n",
      "16079/16079 [==============================] - 35s 2ms/step - loss: 0.1413 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 6/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1410 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 7/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1409 - acc: 0.9684 - val_loss: 0.1321 - val_acc: 0.9709\n",
      "Epoch 8/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1411 - acc: 0.9684 - val_loss: 0.1316 - val_acc: 0.9709\n",
      "Epoch 9/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1416 - acc: 0.9684 - val_loss: 0.1318 - val_acc: 0.9709\n",
      "Epoch 10/10\n",
      "16079/16079 [==============================] - 36s 2ms/step - loss: 0.1411 - acc: 0.9684 - val_loss: 0.1323 - val_acc: 0.9709\n",
      "357.93049907684326 seconds\n"
     ]
    }
   ],
   "source": [
    "# rnn_history = rnn_model.fit(train_X, train_y, epochs=3, batch_size=64)\n",
    "rnn_start = time.time()\n",
    "rnn_history = rnn_model.fit(\n",
    "    train_vectors_df, \n",
    "    train_y_nums, \n",
    "    validation_data=(validation_vectors_df, validation_y_nums), \n",
    "    epochs=10, \n",
    "    batch_size=64\n",
    ")\n",
    "rnn_end = time.time()\n",
    "print(rnn_end - rnn_start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_loss_values = rnn_history.history['loss']\n",
    "rnn_epochs = range(1, len(rnn_loss_values)+1)\n",
    "\n",
    "plt.plot(rnn_epochs, rnn_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_test_y_predictions = rnn_model.predict(validation_vectors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03626591],\n",
       "       [0.03626591],\n",
       "       [0.03626591],\n",
       "       ...,\n",
       "       [0.03626592],\n",
       "       [0.03626592],\n",
       "       [0.03626592]], dtype=float32)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_test_y_predictions[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3988,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "rnn_y_test_class = np.argmax(test_y,axis=1)\n",
    "rnn_y_pred_class = np.argmax(rnn_test_y_predictions,axis=1)\n",
    "\n",
    "assert y_test_class.shape == y_pred_class.shape\n",
    "print(rnn_y_pred_class.shape)\n",
    "print(rnn_y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3872\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3988\n",
      "   macro avg       0.49      0.50      0.49      3988\n",
      "weighted avg       0.94      0.97      0.96      3988\n",
      "\n",
      "[[3872    0]\n",
      " [ 116    0]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_y_nums,rnn_y_pred_class))\n",
    "print(confusion_matrix(validation_y_nums,rnn_y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16079 samples, validate on 3988 samples\n",
      "Epoch 1/100\n",
      " 9728/16079 [=================>............] - ETA: 14s - loss: 0.1351 - acc: 0.9704"
     ]
    }
   ],
   "source": [
    "# rnn_history = rnn_model.fit(train_X, train_y, epochs=3, batch_size=64)\n",
    "rnn_start = time.time()\n",
    "rnn_history = rnn_model.fit(\n",
    "    train_X, \n",
    "    train_y_nums, \n",
    "    validation_data=(validation_X, validation_y_nums), \n",
    "    epochs=100, \n",
    "    batch_size=64\n",
    ")\n",
    "rnn_end = time.time()\n",
    "print(rnn_end - rnn_start, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
