{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras for Word Embedding as well as the LSTM\n",
    "\n",
    "https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470\n",
    "\n",
    "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.layers import Bidirectional, Dense, Dropout, Input, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIR = join(\"..\", \"feature_extraction\", \"feature_outputs\")\n",
    "DATA_FILES_DIR = join(\"..\", \"feature_extraction\", \"data_files\")\n",
    "chat_logs_filename = join(DATA_FILES_DIR, \"gnue_irc_chat_logs_preprocessed.txt\")\n",
    "summarized_chat_date_partitions_filename = join(\n",
    "    DATA_FILES_DIR, \"summarized_chat_date_partitions_cumulative_count.csv\"\n",
    ")\n",
    "summarized_chat_log_ids_filename = join(DATA_FILES_DIR, \"summarized_chat_log_ids.csv\")\n",
    "summarized_chat_features_filename = join(FEATURES_DIR, \"summarized_chats_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_chat_date_partitions = pd.read_csv(summarized_chat_date_partitions_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_log_id</th>\n",
       "      <th>date_of_log</th>\n",
       "      <th>chat_line_count</th>\n",
       "      <th>cumulative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>473197</td>\n",
       "      <td>2001-11-07</td>\n",
       "      <td>1990</td>\n",
       "      <td>16079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>495175</td>\n",
       "      <td>2001-11-13</td>\n",
       "      <td>1051</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>497259</td>\n",
       "      <td>2001-11-14</td>\n",
       "      <td>536</td>\n",
       "      <td>17666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>526307</td>\n",
       "      <td>2001-11-15</td>\n",
       "      <td>1053</td>\n",
       "      <td>18719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>531627</td>\n",
       "      <td>2001-11-12</td>\n",
       "      <td>1348</td>\n",
       "      <td>20067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>579591</td>\n",
       "      <td>2001-10-24</td>\n",
       "      <td>162</td>\n",
       "      <td>20229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>586206</td>\n",
       "      <td>2001-10-23</td>\n",
       "      <td>165</td>\n",
       "      <td>20394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>623684</td>\n",
       "      <td>2001-10-25</td>\n",
       "      <td>321</td>\n",
       "      <td>20715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_log_id date_of_log  chat_line_count  cumulative_count\n",
       "19      473197  2001-11-07             1990             16079\n",
       "20      495175  2001-11-13             1051             17130\n",
       "21      497259  2001-11-14              536             17666\n",
       "22      526307  2001-11-15             1053             18719\n",
       "23      531627  2001-11-12             1348             20067\n",
       "24      579591  2001-10-24              162             20229\n",
       "25      586206  2001-10-23              165             20394\n",
       "26      623684  2001-10-25              321             20715"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_chat_date_partitions.tail(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079\n",
      "20067\n"
     ]
    }
   ],
   "source": [
    "index_for_validation_test_split = summarized_chat_date_partitions.tail(4)[\"cumulative_count\"]\n",
    "index_for_validation_test_split = index_for_validation_test_split.values[0]\n",
    "index_for_train_validation_split = summarized_chat_date_partitions.tail(8)[\"cumulative_count\"]\n",
    "index_for_train_validation_split = index_for_train_validation_split.values[0]\n",
    "print(index_for_train_validation_split)\n",
    "print(index_for_validation_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data using pandas\n",
    "unnormalized_summarized_chat_features_df = pd.read_csv(summarized_chat_features_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>624000</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.281268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>624001</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.444846</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20712</th>\n",
       "      <td>624002</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.306102</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>624003</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>624004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>2.205475</td>\n",
       "      <td>0.630764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "20710  624000                    0.987539                2   \n",
       "20711  624001                    0.990654                4   \n",
       "20712  624002                    0.993769                7   \n",
       "20713  624003                    0.996885                0   \n",
       "20714  624004                    1.000000                1   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "20710                        0           0.0000     0.000432   \n",
       "20711                        0           0.0000     0.000801   \n",
       "20712                        0           0.5267     0.001122   \n",
       "20713                        0           0.4588     0.000000   \n",
       "20714                        0           0.0000     0.000803   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "20710                0.003309     0.983457                0.281268           0  \n",
       "20711                0.006145     0.444846                0.127226           0  \n",
       "20712                0.008603     0.306102                0.087545           0  \n",
       "20713                0.000000     0.000000                0.000000           0  \n",
       "20714                0.006161     2.205475                0.630764           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnormalized_summarized_chat_features_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the chat features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data_max_values = unnormalized_summarized_chat_features_df.max()\n",
    "chat_data_min_values = unnormalized_summarized_chat_features_df.min()\n",
    "max_number_of_special_terms = chat_data_max_values.number_of_special_terms\n",
    "max_sentence_length = chat_data_max_values.sentence_length\n",
    "min_number_of_special_terms = chat_data_min_values.number_of_special_terms\n",
    "min_sentence_length = chat_data_min_values.sentence_length\n",
    "max_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.013699\n",
      "1    0.178082\n",
      "2    0.136986\n",
      "3    0.068493\n",
      "4    0.109589\n",
      "Name: sentence_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>mean_tf_isf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>624000</td>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>0.281268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>624001</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.444846</td>\n",
       "      <td>0.127226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20712</th>\n",
       "      <td>624002</td>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.306102</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>624003</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>624004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>2.205475</td>\n",
       "      <td>0.630764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       log_id  absolute_sentence_position  sentence_length  \\\n",
       "20710  624000                    0.987539         0.027397   \n",
       "20711  624001                    0.990654         0.054795   \n",
       "20712  624002                    0.993769         0.095890   \n",
       "20713  624003                    0.996885         0.000000   \n",
       "20714  624004                    1.000000         0.013699   \n",
       "\n",
       "       number_of_special_terms  sentiment_score  mean_tf_idf  \\\n",
       "20710                      0.0           0.0000     0.000432   \n",
       "20711                      0.0           0.0000     0.000801   \n",
       "20712                      0.0           0.5267     0.001122   \n",
       "20713                      0.0           0.4588     0.000000   \n",
       "20714                      0.0           0.0000     0.000803   \n",
       "\n",
       "       normalized_mean_tf_idf  mean_tf_isf  normalized_mean_tf_isf  is_summary  \n",
       "20710                0.003309     0.983457                0.281268           0  \n",
       "20711                0.006145     0.444846                0.127226           0  \n",
       "20712                0.008603     0.306102                0.087545           0  \n",
       "20713                0.000000     0.000000                0.000000           0  \n",
       "20714                0.006161     2.205475                0.630764           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_log_df = unnormalized_summarized_chat_features_df.copy()\n",
    "chat_log_df.sentence_length = (\n",
    "    chat_log_df.sentence_length - min_sentence_length) / (\n",
    "    max_sentence_length - min_sentence_length)\n",
    "chat_log_df.number_of_special_terms = (\n",
    "    chat_log_df.number_of_special_terms - min_number_of_special_terms) / (\n",
    "    max_number_of_special_terms - min_number_of_special_terms)\n",
    "chat_log_df.reset_index()\n",
    "print(chat_log_df.sentence_length.head())\n",
    "chat_log_df.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20710</th>\n",
       "      <td>0.987539</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.281268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20711</th>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.127226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20712</th>\n",
       "      <td>0.993769</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.087545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20713</th>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20714</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.630764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "20710                    0.987539         0.027397                      0.0   \n",
       "20711                    0.990654         0.054795                      0.0   \n",
       "20712                    0.993769         0.095890                      0.0   \n",
       "20713                    0.996885         0.000000                      0.0   \n",
       "20714                    1.000000         0.013699                      0.0   \n",
       "\n",
       "       sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "20710           0.0000                0.003309                0.281268  \n",
       "20711           0.0000                0.006145                0.127226  \n",
       "20712           0.5267                0.008603                0.087545  \n",
       "20713           0.4588                0.000000                0.000000  \n",
       "20714           0.0000                0.006161                0.630764  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unneeded columns. Keep only normalized columns\n",
    "columns_to_drop = [\"log_id\", \"is_summary\", \"mean_tf_idf\", \"mean_tf_isf\"]\n",
    "chat_log_df = chat_log_df.drop(columns=columns_to_drop)\n",
    "chat_log_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20067</th>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.028675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20068</th>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.315960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.183785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.272912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "20067                    0.006173         0.232877                      0.0   \n",
       "20068                    0.012346         0.027397                      0.0   \n",
       "20069                    0.018519         0.041096                      0.0   \n",
       "20070                    0.024691         0.000000                      0.0   \n",
       "20071                    0.030864         0.027397                      0.0   \n",
       "\n",
       "       sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "20067           0.5994                0.004672                0.028675  \n",
       "20068          -0.2960                0.000686                0.315960  \n",
       "20069          -0.2960                0.003367                0.183785  \n",
       "20070          -0.4404                0.000000                0.000000  \n",
       "20071           0.0000                0.004243                0.272912  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_X = chat_log_df.iloc[:index_for_train_validation_split]\n",
    "validation_features_X = chat_log_df.iloc[index_for_train_validation_split:index_for_validation_test_split]\n",
    "test_features_X = chat_log_df.iloc[index_for_validation_test_split:]\n",
    "train_features_X.tail()\n",
    "\n",
    "assert train_features_X.shape[1] == test_features_X.shape[1] \n",
    "assert test_features_X.shape[1] == validation_features_X.shape[1] \n",
    "print(test_features_X.shape)\n",
    "test_features_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_chat_log_ids = pd.read_csv(\n",
    "    summarized_chat_log_ids_filename,\n",
    "    names=[\"log_id\", \"is_summary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>is_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_id  is_summary\n",
       "0   85350           0\n",
       "1   85351           0\n",
       "2   85352           0\n",
       "3   85353           0\n",
       "4   85354           0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_chat_log_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarized_chat_logs(chat_logs_filename, summarized_chat_log_ids):\n",
    "    summarized_chat_log_ids = set(summarized_chat_log_ids)\n",
    "    chats = []\n",
    "    with open(chat_logs_filename) as chat_logs:\n",
    "        line_number = 1\n",
    "        for chat_log in chat_logs:\n",
    "            if line_number in summarized_chat_log_ids:\n",
    "                chats.append(chat_log)\n",
    "            line_number += 1\n",
    "    return chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great\\n',\n",
       " 'i dont recall you ever telling me what you do at your job\\n',\n",
       " \"and you probably can't be persuaded to tell me now.\\n\",\n",
       " 'due to your persistant funkitude\\n',\n",
       " 'umm, he sits around on irc all day ;)\\n']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_logs = get_summarized_chat_logs(chat_logs_filename, summarized_chat_log_ids.log_id.values)\n",
    "chat_logs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tokenizer Object\n",
    "tokenizer = Tokenizer(\n",
    "    num_words=None,\n",
    "    filters=\"\\n\",\n",
    "    lower = False, \n",
    "    split = ' '\n",
    ")\n",
    "tokenizer.fit_on_texts(chat_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(chat_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3099, 72, 4137, 300, 16, 584, 34, 309, 54]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indexes = tokenizer.index_word\n",
    "def get_words_at_line_number(word_indexes, line_number):\n",
    "    return \" \".join(word_indexes[word] for word in sequences[line_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and you probably can't be persuaded to tell me now.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_at_line_number(word_indexes, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079,)\n",
      "(648,)\n",
      "[list([547])]\n",
      "648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([107, 18365]), list([128, 9, 31, 1456]),\n",
       "       list([18366, 342, 36, 3591, 515, 29, 18367, 14]), list([14]),\n",
       "       list([1454])], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array(sequences[:index_for_train_validation_split])\n",
    "validation_X = np.array(sequences[index_for_train_validation_split:index_for_validation_test_split])\n",
    "test_X = np.array(sequences[index_for_validation_test_split:])\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_X[:1])\n",
    "print(len(test_X))\n",
    "test_X[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one hot encoding for the target column\n",
    "chat_log_labels = to_categorical(summarized_chat_log_ids.is_summary)\n",
    "\n",
    "train_y = chat_log_labels[:index_for_train_validation_split]\n",
    "validation_y = chat_log_labels[index_for_train_validation_split:index_for_validation_test_split]\n",
    "test_y = chat_log_labels[index_for_validation_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[85:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad input sequences\n",
    "max_chat_length = max(len(seq) for seq in sequences)\n",
    "train_X = sequence.pad_sequences(train_X, maxlen=max_chat_length)\n",
    "validation_X = sequence.pad_sequences(validation_X, maxlen=max_chat_length)\n",
    "test_X = sequence.pad_sequences(test_X, maxlen=max_chat_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16079, 73)\n",
      "(648, 73)\n",
      "(3988, 73)\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     4  1575    20   103    15     3 15875   908    12   125  1051\n",
      "    14]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(validation_X.shape)\n",
    "print(validation_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "top_words = 100000\n",
    "embedding_vecor_length = 32\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(top_words, embedding_vecor_length, input_length=max_chat_length))\n",
    "# model.add(Bidirectional(LSTM(100), input_shape=(max_chat_length, 1)))\n",
    "# model.add((LSTM(100))\n",
    "# model.add(Dense(2, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a tensor\n",
    "# inputs = Input(shape=(784,))\n",
    "# # a layer instance is callable on a tensor, and returns a tensor\n",
    "# x = Dense(64, activation='relu')(inputs)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# # This creates a model that includes\n",
    "# # the Input layer and three Dense layers\n",
    "# model = Model(inputs=inputs, outputs=predictions)\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit(data, labels)  # starts training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wcyn/anaconda3/envs/gnue-irc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Sentence input: meant to receive sequences of `max_chat_length` integers, between 1 and `top_words`.\n",
    "decoder_inputs = Input(shape=(max_chat_length,), dtype='int32', name='main_sentence_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "num_of_decoder_tokens = 512\n",
    "x = Embedding(output_dim=num_of_decoder_tokens, input_dim=top_words, input_length=max_chat_length)(decoder_inputs)\n",
    "\n",
    "# An LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "x, state_h, state_c = LSTM(32, return_state=True)(x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "x = Embedding(output_dim=num_of_decoder_tokens, input_dim=top_words)(decoder_inputs)\n",
    "x = LSTM(top_words, return_sequences=True)(x, initial_state=encoder_states)\n",
    "decoder_outputs = Dense(num_of_decoder_tokens, activation='softmax')(x)\n",
    "\n",
    "# Define the model that will turn `encoder_input_data` & `decoder_input_data` \n",
    "# into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)nt q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we insert the auxiliary loss, allowing the LSTM and Embedding layer \n",
    "# to be trained smoothly even though the main loss will be much higher in the model.\n",
    "auxiliary_output = Dense(32, name='aux_output')(lstm_out)\n",
    "\n",
    "# At this point, we feed into the model our auxiliary input data by \n",
    "# concatenating it with the LSTM output\n",
    "num_of_feature_columns = test_features_X.shape[1]\n",
    "sentence_features_input = Input(shape=(num_of_feature_columns,), name='sentence_features_input')\n",
    "merged_input_and_output = keras.layers.concatenate([lstm_out, sentence_features_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(merged_input_and_output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(2, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model with two inputs and two outputs\n",
    "merged_model = Model(\n",
    "    inputs=[main_sentence_input, sentence_features_input], \n",
    "    outputs=[main_output, auxiliary_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_sentence_input (InputLayer (None, 73)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 73, 512)      51200000    main_sentence_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (None, 32)           69760       embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sentence_features_input (InputL (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           lstm_11[0][0]                    \n",
      "                                                                 sentence_features_input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           2496        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64)           4160        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           4160        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            130         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 2)            66          lstm_11[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,280,772\n",
      "Trainable params: 51,280,772\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merged_model.compile(\n",
    "    # optimizer='rmsprop', \n",
    "    optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    loss_weights=[1., 0.2]\n",
    ")\n",
    "merged_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16079 samples, validate on 3988 samples\n",
      "Epoch 1/100\n",
      "16079/16079 [==============================] - 216s 13ms/step - loss: 0.0140 - main_output_loss: 0.0113 - aux_output_loss: 0.0136 - val_loss: 0.3317 - val_main_output_loss: 0.2863 - val_aux_output_loss: 0.2268\n",
      "Epoch 2/100\n",
      "16079/16079 [==============================] - 232s 14ms/step - loss: 0.0130 - main_output_loss: 0.0104 - aux_output_loss: 0.0128 - val_loss: 0.4219 - val_main_output_loss: 0.3702 - val_aux_output_loss: 0.2589\n",
      "Epoch 3/100\n",
      "16079/16079 [==============================] - 210s 13ms/step - loss: 0.0099 - main_output_loss: 0.0080 - aux_output_loss: 0.0097 - val_loss: 0.4401 - val_main_output_loss: 0.3871 - val_aux_output_loss: 0.2652\n",
      "Epoch 4/100\n",
      "16079/16079 [==============================] - 226s 14ms/step - loss: 0.0101 - main_output_loss: 0.0081 - aux_output_loss: 0.0098 - val_loss: 0.4425 - val_main_output_loss: 0.3894 - val_aux_output_loss: 0.2653\n",
      "Epoch 5/100\n",
      "16079/16079 [==============================] - 205s 13ms/step - loss: 0.0078 - main_output_loss: 0.0062 - aux_output_loss: 0.0079 - val_loss: 0.5977 - val_main_output_loss: 0.5368 - val_aux_output_loss: 0.3049\n",
      "Epoch 6/100\n",
      "16079/16079 [==============================] - 200s 12ms/step - loss: 0.0069 - main_output_loss: 0.0056 - aux_output_loss: 0.0064 - val_loss: 0.5223 - val_main_output_loss: 0.4615 - val_aux_output_loss: 0.3041\n",
      "Epoch 7/100\n",
      "16079/16079 [==============================] - 200s 12ms/step - loss: 0.0061 - main_output_loss: 0.0049 - aux_output_loss: 0.0057 - val_loss: 0.5457 - val_main_output_loss: 0.4825 - val_aux_output_loss: 0.3159\n",
      "Epoch 8/100\n",
      "16079/16079 [==============================] - 209s 13ms/step - loss: 0.0056 - main_output_loss: 0.0045 - aux_output_loss: 0.0053 - val_loss: 0.6334 - val_main_output_loss: 0.5640 - val_aux_output_loss: 0.3470\n",
      "Epoch 9/100\n",
      "16079/16079 [==============================] - 210s 13ms/step - loss: 0.0053 - main_output_loss: 0.0043 - aux_output_loss: 0.0049 - val_loss: 0.6208 - val_main_output_loss: 0.5511 - val_aux_output_loss: 0.3484\n",
      "Epoch 10/100\n",
      "16079/16079 [==============================] - 247s 15ms/step - loss: 0.0051 - main_output_loss: 0.0041 - aux_output_loss: 0.0047 - val_loss: 0.6758 - val_main_output_loss: 0.6019 - val_aux_output_loss: 0.3696\n",
      "Epoch 11/100\n",
      "16079/16079 [==============================] - 202s 13ms/step - loss: 0.0050 - main_output_loss: 0.0040 - aux_output_loss: 0.0046 - val_loss: 0.7001 - val_main_output_loss: 0.6251 - val_aux_output_loss: 0.3750\n",
      "Epoch 12/100\n",
      "16079/16079 [==============================] - 205s 13ms/step - loss: 0.0049 - main_output_loss: 0.0041 - aux_output_loss: 0.0044 - val_loss: 0.7097 - val_main_output_loss: 0.6337 - val_aux_output_loss: 0.3801\n",
      "Epoch 13/100\n",
      "16079/16079 [==============================] - 201s 12ms/step - loss: 0.0049 - main_output_loss: 0.0041 - aux_output_loss: 0.0044 - val_loss: 0.7236 - val_main_output_loss: 0.6464 - val_aux_output_loss: 0.3862\n",
      "Epoch 14/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0048 - main_output_loss: 0.0039 - aux_output_loss: 0.0043 - val_loss: 1.0003 - val_main_output_loss: 0.9079 - val_aux_output_loss: 0.4621\n",
      "Epoch 15/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0118 - main_output_loss: 0.0099 - aux_output_loss: 0.0095 - val_loss: 0.4890 - val_main_output_loss: 0.4207 - val_aux_output_loss: 0.3412\n",
      "Epoch 16/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0109 - main_output_loss: 0.0090 - aux_output_loss: 0.0095 - val_loss: 0.6709 - val_main_output_loss: 0.5867 - val_aux_output_loss: 0.4210\n",
      "Epoch 17/100\n",
      "16079/16079 [==============================] - 200s 12ms/step - loss: 0.0081 - main_output_loss: 0.0067 - aux_output_loss: 0.0071 - val_loss: 0.5347 - val_main_output_loss: 0.4640 - val_aux_output_loss: 0.3535\n",
      "Epoch 18/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0076 - main_output_loss: 0.0063 - aux_output_loss: 0.0062 - val_loss: 0.5427 - val_main_output_loss: 0.4683 - val_aux_output_loss: 0.3718\n",
      "Epoch 19/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0048 - main_output_loss: 0.0039 - aux_output_loss: 0.0043 - val_loss: 0.6637 - val_main_output_loss: 0.5848 - val_aux_output_loss: 0.3945\n",
      "Epoch 20/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0048 - main_output_loss: 0.0040 - aux_output_loss: 0.0042 - val_loss: 0.6116 - val_main_output_loss: 0.5349 - val_aux_output_loss: 0.3837\n",
      "Epoch 21/100\n",
      "16079/16079 [==============================] - 201s 12ms/step - loss: 0.0045 - main_output_loss: 0.0037 - aux_output_loss: 0.0041 - val_loss: 0.6314 - val_main_output_loss: 0.5506 - val_aux_output_loss: 0.4041\n",
      "Epoch 22/100\n",
      "16079/16079 [==============================] - 201s 13ms/step - loss: 0.0047 - main_output_loss: 0.0039 - aux_output_loss: 0.0040 - val_loss: 0.7232 - val_main_output_loss: 0.6396 - val_aux_output_loss: 0.4180\n",
      "Epoch 23/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0039 - val_loss: 0.7525 - val_main_output_loss: 0.6663 - val_aux_output_loss: 0.4310\n",
      "Epoch 24/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0044 - main_output_loss: 0.0037 - aux_output_loss: 0.0039 - val_loss: 0.7297 - val_main_output_loss: 0.6430 - val_aux_output_loss: 0.4338\n",
      "Epoch 25/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0043 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.7092 - val_main_output_loss: 0.6203 - val_aux_output_loss: 0.4446\n",
      "Epoch 26/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0045 - main_output_loss: 0.0037 - aux_output_loss: 0.0038 - val_loss: 0.7305 - val_main_output_loss: 0.6404 - val_aux_output_loss: 0.4503\n",
      "Epoch 27/100\n",
      "16079/16079 [==============================] - 199s 12ms/step - loss: 0.0042 - main_output_loss: 0.0034 - aux_output_loss: 0.0037 - val_loss: 0.7716 - val_main_output_loss: 0.6797 - val_aux_output_loss: 0.4594\n",
      "Epoch 28/100\n",
      "16079/16079 [==============================] - 200s 12ms/step - loss: 0.0044 - main_output_loss: 0.0037 - aux_output_loss: 0.0039 - val_loss: 0.7780 - val_main_output_loss: 0.6829 - val_aux_output_loss: 0.4752\n",
      "Epoch 29/100\n",
      "16079/16079 [==============================] - 203s 13ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.7670 - val_main_output_loss: 0.6736 - val_aux_output_loss: 0.4673\n",
      "Epoch 30/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.7675 - val_main_output_loss: 0.6727 - val_aux_output_loss: 0.4739\n",
      "Epoch 31/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0048 - main_output_loss: 0.0040 - aux_output_loss: 0.0039 - val_loss: 0.8402 - val_main_output_loss: 0.7386 - val_aux_output_loss: 0.5083\n",
      "Epoch 32/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0064 - main_output_loss: 0.0054 - aux_output_loss: 0.0050 - val_loss: 0.5477 - val_main_output_loss: 0.4670 - val_aux_output_loss: 0.4033\n",
      "Epoch 33/100\n",
      "16079/16079 [==============================] - 201s 12ms/step - loss: 0.0095 - main_output_loss: 0.0080 - aux_output_loss: 0.0075 - val_loss: 0.5465 - val_main_output_loss: 0.4637 - val_aux_output_loss: 0.4137\n",
      "Epoch 34/100\n",
      "16079/16079 [==============================] - 214s 13ms/step - loss: 0.0054 - main_output_loss: 0.0044 - aux_output_loss: 0.0048 - val_loss: 0.6039 - val_main_output_loss: 0.5239 - val_aux_output_loss: 0.4000\n",
      "Epoch 35/100\n",
      "16079/16079 [==============================] - 218s 14ms/step - loss: 0.0046 - main_output_loss: 0.0038 - aux_output_loss: 0.0041 - val_loss: 0.6547 - val_main_output_loss: 0.5727 - val_aux_output_loss: 0.4099\n",
      "Epoch 36/100\n",
      "16079/16079 [==============================] - 230s 14ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.6168 - val_main_output_loss: 0.5339 - val_aux_output_loss: 0.4144\n",
      "Epoch 37/100\n",
      "16079/16079 [==============================] - 214s 13ms/step - loss: 0.0045 - main_output_loss: 0.0038 - aux_output_loss: 0.0038 - val_loss: 0.6726 - val_main_output_loss: 0.5878 - val_aux_output_loss: 0.4241\n",
      "Epoch 38/100\n",
      "16079/16079 [==============================] - 209s 13ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0037 - val_loss: 0.6838 - val_main_output_loss: 0.5974 - val_aux_output_loss: 0.4320\n",
      "Epoch 39/100\n",
      "16079/16079 [==============================] - 199s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0037 - val_loss: 0.7153 - val_main_output_loss: 0.6270 - val_aux_output_loss: 0.4418\n",
      "Epoch 40/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0047 - main_output_loss: 0.0039 - aux_output_loss: 0.0040 - val_loss: 0.6209 - val_main_output_loss: 0.5333 - val_aux_output_loss: 0.4379\n",
      "Epoch 41/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0045 - main_output_loss: 0.0038 - aux_output_loss: 0.0038 - val_loss: 0.8470 - val_main_output_loss: 0.7466 - val_aux_output_loss: 0.5019\n",
      "Epoch 42/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0062 - main_output_loss: 0.0053 - aux_output_loss: 0.0049 - val_loss: 0.6051 - val_main_output_loss: 0.5185 - val_aux_output_loss: 0.4331\n",
      "Epoch 43/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0048 - main_output_loss: 0.0040 - aux_output_loss: 0.0040 - val_loss: 0.7475 - val_main_output_loss: 0.6543 - val_aux_output_loss: 0.4659\n",
      "Epoch 44/100\n",
      "16079/16079 [==============================] - 199s 12ms/step - loss: 0.0043 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.7705 - val_main_output_loss: 0.6761 - val_aux_output_loss: 0.4721\n",
      "Epoch 45/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0043 - main_output_loss: 0.0035 - aux_output_loss: 0.0037 - val_loss: 0.7422 - val_main_output_loss: 0.6472 - val_aux_output_loss: 0.4751\n",
      "Epoch 46/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0037 - val_loss: 0.8116 - val_main_output_loss: 0.7154 - val_aux_output_loss: 0.4811\n",
      "Epoch 47/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.7994 - val_main_output_loss: 0.7024 - val_aux_output_loss: 0.4849\n",
      "Epoch 48/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0043 - main_output_loss: 0.0035 - aux_output_loss: 0.0038 - val_loss: 0.8127 - val_main_output_loss: 0.7154 - val_aux_output_loss: 0.4868\n",
      "Epoch 49/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0036 - val_loss: 0.7913 - val_main_output_loss: 0.6929 - val_aux_output_loss: 0.4919\n",
      "Epoch 50/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.8123 - val_main_output_loss: 0.7122 - val_aux_output_loss: 0.5003\n",
      "Epoch 51/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0034 - aux_output_loss: 0.0037 - val_loss: 0.8338 - val_main_output_loss: 0.7328 - val_aux_output_loss: 0.5050\n",
      "Epoch 52/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.8360 - val_main_output_loss: 0.7345 - val_aux_output_loss: 0.5074\n",
      "Epoch 53/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0054 - main_output_loss: 0.0046 - aux_output_loss: 0.0043 - val_loss: 0.6903 - val_main_output_loss: 0.5908 - val_aux_output_loss: 0.4977\n",
      "Epoch 54/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0045 - main_output_loss: 0.0038 - aux_output_loss: 0.0038 - val_loss: 1.0689 - val_main_output_loss: 0.9525 - val_aux_output_loss: 0.5819\n",
      "Epoch 55/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0078 - main_output_loss: 0.0067 - aux_output_loss: 0.0057 - val_loss: 0.5548 - val_main_output_loss: 0.4595 - val_aux_output_loss: 0.4766\n",
      "Epoch 56/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0058 - main_output_loss: 0.0049 - aux_output_loss: 0.0047 - val_loss: 0.7685 - val_main_output_loss: 0.6625 - val_aux_output_loss: 0.5296\n",
      "Epoch 57/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0073 - main_output_loss: 0.0061 - aux_output_loss: 0.0058 - val_loss: 0.7002 - val_main_output_loss: 0.5981 - val_aux_output_loss: 0.5107\n",
      "Epoch 58/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0043 - main_output_loss: 0.0035 - aux_output_loss: 0.0038 - val_loss: 0.7363 - val_main_output_loss: 0.6353 - val_aux_output_loss: 0.5049\n",
      "Epoch 59/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.7574 - val_main_output_loss: 0.6545 - val_aux_output_loss: 0.5145\n",
      "Epoch 60/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.7648 - val_main_output_loss: 0.6611 - val_aux_output_loss: 0.5184\n",
      "Epoch 61/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0042 - main_output_loss: 0.0034 - aux_output_loss: 0.0036 - val_loss: 0.7774 - val_main_output_loss: 0.6735 - val_aux_output_loss: 0.5196\n",
      "Epoch 62/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.7941 - val_main_output_loss: 0.6898 - val_aux_output_loss: 0.5216\n",
      "Epoch 63/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0040 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.7457 - val_main_output_loss: 0.6408 - val_aux_output_loss: 0.5246\n",
      "Epoch 64/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.8035 - val_main_output_loss: 0.6978 - val_aux_output_loss: 0.5287\n",
      "Epoch 65/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0041 - main_output_loss: 0.0033 - aux_output_loss: 0.0036 - val_loss: 0.8140 - val_main_output_loss: 0.7080 - val_aux_output_loss: 0.5304\n",
      "Epoch 66/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0034 - aux_output_loss: 0.0036 - val_loss: 0.8114 - val_main_output_loss: 0.7047 - val_aux_output_loss: 0.5337\n",
      "Epoch 67/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0041 - main_output_loss: 0.0034 - aux_output_loss: 0.0036 - val_loss: 0.8139 - val_main_output_loss: 0.7065 - val_aux_output_loss: 0.5370\n",
      "Epoch 68/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0041 - main_output_loss: 0.0034 - aux_output_loss: 0.0035 - val_loss: 0.7978 - val_main_output_loss: 0.6900 - val_aux_output_loss: 0.5392\n",
      "Epoch 69/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0036 - val_loss: 0.7946 - val_main_output_loss: 0.6871 - val_aux_output_loss: 0.5373\n",
      "Epoch 70/100\n",
      "16079/16079 [==============================] - 193s 12ms/step - loss: 0.0049 - main_output_loss: 0.0041 - aux_output_loss: 0.0038 - val_loss: 0.7690 - val_main_output_loss: 0.6599 - val_aux_output_loss: 0.5454\n",
      "Epoch 71/100\n",
      "16079/16079 [==============================] - 193s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0035 - val_loss: 0.7833 - val_main_output_loss: 0.6742 - val_aux_output_loss: 0.5454\n",
      "Epoch 72/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0046 - main_output_loss: 0.0038 - aux_output_loss: 0.0038 - val_loss: 0.7159 - val_main_output_loss: 0.6075 - val_aux_output_loss: 0.5417\n",
      "Epoch 73/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0045 - main_output_loss: 0.0037 - aux_output_loss: 0.0038 - val_loss: 0.7512 - val_main_output_loss: 0.6419 - val_aux_output_loss: 0.5462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0042 - main_output_loss: 0.0035 - aux_output_loss: 0.0035 - val_loss: 0.7795 - val_main_output_loss: 0.6710 - val_aux_output_loss: 0.5424\n",
      "Epoch 75/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0041 - main_output_loss: 0.0034 - aux_output_loss: 0.0036 - val_loss: 0.8254 - val_main_output_loss: 0.7149 - val_aux_output_loss: 0.5525\n",
      "Epoch 76/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0041 - main_output_loss: 0.0034 - aux_output_loss: 0.0035 - val_loss: 0.8360 - val_main_output_loss: 0.7250 - val_aux_output_loss: 0.5551\n",
      "Epoch 77/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0041 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.8356 - val_main_output_loss: 0.7237 - val_aux_output_loss: 0.5595\n",
      "Epoch 78/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0039 - main_output_loss: 0.0032 - aux_output_loss: 0.0035 - val_loss: 0.8453 - val_main_output_loss: 0.7322 - val_aux_output_loss: 0.5655\n",
      "Epoch 79/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0040 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.8927 - val_main_output_loss: 0.7786 - val_aux_output_loss: 0.5704\n",
      "Epoch 80/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0040 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.8630 - val_main_output_loss: 0.7511 - val_aux_output_loss: 0.5595\n",
      "Epoch 81/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0042 - main_output_loss: 0.0034 - aux_output_loss: 0.0037 - val_loss: 0.9367 - val_main_output_loss: 0.8170 - val_aux_output_loss: 0.5984\n",
      "Epoch 82/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0040 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.8826 - val_main_output_loss: 0.7689 - val_aux_output_loss: 0.5683\n",
      "Epoch 83/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0039 - main_output_loss: 0.0032 - aux_output_loss: 0.0035 - val_loss: 0.9093 - val_main_output_loss: 0.7933 - val_aux_output_loss: 0.5800\n",
      "Epoch 84/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0039 - main_output_loss: 0.0032 - aux_output_loss: 0.0035 - val_loss: 0.9045 - val_main_output_loss: 0.7885 - val_aux_output_loss: 0.5802\n",
      "Epoch 85/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0040 - main_output_loss: 0.0032 - aux_output_loss: 0.0036 - val_loss: 0.9040 - val_main_output_loss: 0.7894 - val_aux_output_loss: 0.5727\n",
      "Epoch 86/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0040 - main_output_loss: 0.0033 - aux_output_loss: 0.0035 - val_loss: 0.8846 - val_main_output_loss: 0.7695 - val_aux_output_loss: 0.5756\n",
      "Epoch 87/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0038 - val_loss: 0.9180 - val_main_output_loss: 0.8074 - val_aux_output_loss: 0.5532\n",
      "Epoch 88/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0048 - main_output_loss: 0.0041 - aux_output_loss: 0.0038 - val_loss: 0.8598 - val_main_output_loss: 0.7590 - val_aux_output_loss: 0.5041\n",
      "Epoch 89/100\n",
      "16079/16079 [==============================] - 198s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0039 - val_loss: 1.0106 - val_main_output_loss: 0.8882 - val_aux_output_loss: 0.6121\n",
      "Epoch 90/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0077 - main_output_loss: 0.0065 - aux_output_loss: 0.0062 - val_loss: 0.8089 - val_main_output_loss: 0.6925 - val_aux_output_loss: 0.5824\n",
      "Epoch 91/100\n",
      "16079/16079 [==============================] - 193s 12ms/step - loss: 0.0046 - main_output_loss: 0.0038 - aux_output_loss: 0.0041 - val_loss: 0.8285 - val_main_output_loss: 0.7091 - val_aux_output_loss: 0.5968\n",
      "Epoch 92/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0044 - main_output_loss: 0.0036 - aux_output_loss: 0.0039 - val_loss: 0.8340 - val_main_output_loss: 0.7283 - val_aux_output_loss: 0.5286\n",
      "Epoch 93/100\n",
      "16079/16079 [==============================] - 197s 12ms/step - loss: 0.0038 - main_output_loss: 0.0031 - aux_output_loss: 0.0035 - val_loss: 0.9153 - val_main_output_loss: 0.8048 - val_aux_output_loss: 0.5525\n",
      "Epoch 94/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0037 - main_output_loss: 0.0030 - aux_output_loss: 0.0035 - val_loss: 0.9101 - val_main_output_loss: 0.7996 - val_aux_output_loss: 0.5525\n",
      "Epoch 95/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0038 - main_output_loss: 0.0031 - aux_output_loss: 0.0035 - val_loss: 0.9024 - val_main_output_loss: 0.7916 - val_aux_output_loss: 0.5541\n",
      "Epoch 96/100\n",
      "16079/16079 [==============================] - 193s 12ms/step - loss: 0.0039 - main_output_loss: 0.0032 - aux_output_loss: 0.0035 - val_loss: 0.9059 - val_main_output_loss: 0.7951 - val_aux_output_loss: 0.5541\n",
      "Epoch 97/100\n",
      "16079/16079 [==============================] - 195s 12ms/step - loss: 0.0038 - main_output_loss: 0.0031 - aux_output_loss: 0.0035 - val_loss: 0.8982 - val_main_output_loss: 0.7868 - val_aux_output_loss: 0.5570\n",
      "Epoch 98/100\n",
      "16079/16079 [==============================] - 191s 12ms/step - loss: 0.0041 - main_output_loss: 0.0034 - aux_output_loss: 0.0036 - val_loss: 0.9031 - val_main_output_loss: 0.7917 - val_aux_output_loss: 0.5572\n",
      "Epoch 99/100\n",
      "16079/16079 [==============================] - 196s 12ms/step - loss: 0.0039 - main_output_loss: 0.0032 - aux_output_loss: 0.0036 - val_loss: 0.9271 - val_main_output_loss: 0.8159 - val_aux_output_loss: 0.5557\n",
      "Epoch 100/100\n",
      "16079/16079 [==============================] - 194s 12ms/step - loss: 0.0038 - main_output_loss: 0.0031 - aux_output_loss: 0.0035 - val_loss: 0.9086 - val_main_output_loss: 0.7962 - val_aux_output_loss: 0.5620\n",
      "19960.996418952942  seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model by passing it lists of input arrays and target arrays\n",
    "start = time.time()\n",
    "merged_model_history = merged_model.fit(\n",
    "    [train_X, train_features_X], \n",
    "    [train_y, train_y],\n",
    "    # validation_split=0.2,\n",
    "    validation_data=[\n",
    "        [validation_X, validation_features_X], \n",
    "        [validation_y, validation_y]\n",
    "    ],\n",
    "    epochs=100, \n",
    "    batch_size=64\n",
    ")\n",
    "end = time.time()\n",
    "print(end - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_model_loss_values = merged_model_history.history['loss']\n",
    "merged_model_epochs = range(1, len(merged_model_loss_values)+1)\n",
    "\n",
    "plt.plot(merged_model_epochs, merged_model_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 73, 32)            3200000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               106400    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 3,306,802\n",
      "Trainable params: 3,306,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16079 samples, validate on 3988 samples\n",
      "Epoch 1/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0165 - acc: 0.9940 - val_loss: 0.2794 - val_acc: 0.9431\n",
      "Epoch 2/100\n",
      "16079/16079 [==============================] - 32s 2ms/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.3203 - val_acc: 0.9361\n",
      "Epoch 3/100\n",
      "16079/16079 [==============================] - 35s 2ms/step - loss: 0.0132 - acc: 0.9952 - val_loss: 0.3589 - val_acc: 0.9348\n",
      "Epoch 4/100\n",
      "16079/16079 [==============================] - 34s 2ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.3636 - val_acc: 0.9366\n",
      "Epoch 5/100\n",
      "16079/16079 [==============================] - 39s 2ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.3835 - val_acc: 0.9318\n",
      "Epoch 6/100\n",
      "16079/16079 [==============================] - 33s 2ms/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.4015 - val_acc: 0.9258\n",
      "Epoch 7/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.3782 - val_acc: 0.9393\n",
      "Epoch 8/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0092 - acc: 0.9965 - val_loss: 0.4525 - val_acc: 0.9208\n",
      "Epoch 9/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0078 - acc: 0.9970 - val_loss: 0.4329 - val_acc: 0.9368\n",
      "Epoch 10/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0090 - acc: 0.9966 - val_loss: 0.4051 - val_acc: 0.9310\n",
      "Epoch 11/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.4347 - val_acc: 0.9215\n",
      "Epoch 12/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0077 - acc: 0.9969 - val_loss: 0.3947 - val_acc: 0.9373\n",
      "Epoch 13/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0065 - acc: 0.9976 - val_loss: 0.4293 - val_acc: 0.9411\n",
      "Epoch 14/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0066 - acc: 0.9976 - val_loss: 0.4622 - val_acc: 0.9353\n",
      "Epoch 15/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.4033 - val_acc: 0.9386\n",
      "Epoch 16/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.4126 - val_acc: 0.9285\n",
      "Epoch 17/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 0.3712 - val_acc: 0.9411\n",
      "Epoch 18/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.3709 - val_acc: 0.9506\n",
      "Epoch 19/100\n",
      "16079/16079 [==============================] - 33s 2ms/step - loss: 0.0056 - acc: 0.9975 - val_loss: 0.4331 - val_acc: 0.9408\n",
      "Epoch 20/100\n",
      "16079/16079 [==============================] - 32s 2ms/step - loss: 0.0062 - acc: 0.9973 - val_loss: 0.4221 - val_acc: 0.9433\n",
      "Epoch 21/100\n",
      "16079/16079 [==============================] - 33s 2ms/step - loss: 0.0059 - acc: 0.9974 - val_loss: 0.4397 - val_acc: 0.9373\n",
      "Epoch 22/100\n",
      "16079/16079 [==============================] - 32s 2ms/step - loss: 0.0053 - acc: 0.9976 - val_loss: 0.4510 - val_acc: 0.9378\n",
      "Epoch 23/100\n",
      "16079/16079 [==============================] - 31s 2ms/step - loss: 0.0051 - acc: 0.9977 - val_loss: 0.4899 - val_acc: 0.9303\n",
      "Epoch 24/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0052 - acc: 0.9974 - val_loss: 0.4779 - val_acc: 0.9275\n",
      "Epoch 25/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0050 - acc: 0.9975 - val_loss: 0.5221 - val_acc: 0.9238\n",
      "Epoch 26/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0055 - acc: 0.9977 - val_loss: 0.4763 - val_acc: 0.9293\n",
      "Epoch 27/100\n",
      "16079/16079 [==============================] - 29s 2ms/step - loss: 0.0055 - acc: 0.9973 - val_loss: 0.3879 - val_acc: 0.9483\n",
      "Epoch 28/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0056 - acc: 0.9974 - val_loss: 0.4332 - val_acc: 0.9386\n",
      "Epoch 29/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0049 - acc: 0.9976 - val_loss: 0.4817 - val_acc: 0.9338\n",
      "Epoch 30/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0049 - acc: 0.9976 - val_loss: 0.4578 - val_acc: 0.9398\n",
      "Epoch 31/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0058 - acc: 0.9975 - val_loss: 0.4817 - val_acc: 0.9285\n",
      "Epoch 32/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0045 - acc: 0.9976 - val_loss: 0.4691 - val_acc: 0.9328\n",
      "Epoch 33/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0044 - acc: 0.9979 - val_loss: 0.4760 - val_acc: 0.9366\n",
      "Epoch 34/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0046 - acc: 0.9978 - val_loss: 0.4664 - val_acc: 0.9368\n",
      "Epoch 35/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0046 - acc: 0.9980 - val_loss: 0.4637 - val_acc: 0.9356\n",
      "Epoch 36/100\n",
      "16079/16079 [==============================] - 29s 2ms/step - loss: 0.0042 - acc: 0.9978 - val_loss: 0.4767 - val_acc: 0.9396\n",
      "Epoch 37/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0043 - acc: 0.9979 - val_loss: 0.5182 - val_acc: 0.9300\n",
      "Epoch 38/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0043 - acc: 0.9977 - val_loss: 0.5084 - val_acc: 0.9330\n",
      "Epoch 39/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0042 - acc: 0.9978 - val_loss: 0.4979 - val_acc: 0.9396\n",
      "Epoch 40/100\n",
      "16079/16079 [==============================] - 29s 2ms/step - loss: 0.0042 - acc: 0.9977 - val_loss: 0.4933 - val_acc: 0.9408\n",
      "Epoch 41/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0042 - acc: 0.9975 - val_loss: 0.5338 - val_acc: 0.9328\n",
      "Epoch 42/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0041 - acc: 0.9979 - val_loss: 0.5135 - val_acc: 0.9383\n",
      "Epoch 43/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.3735 - val_acc: 0.9531\n",
      "Epoch 44/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.4025 - val_acc: 0.9466\n",
      "Epoch 45/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0043 - acc: 0.9980 - val_loss: 0.4515 - val_acc: 0.9381\n",
      "Epoch 46/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 0.4635 - val_acc: 0.9378\n",
      "Epoch 47/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0040 - acc: 0.9976 - val_loss: 0.4720 - val_acc: 0.9381\n",
      "Epoch 48/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0040 - acc: 0.9975 - val_loss: 0.4736 - val_acc: 0.9393\n",
      "Epoch 49/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0040 - acc: 0.9976 - val_loss: 0.4763 - val_acc: 0.9388\n",
      "Epoch 50/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 0.4645 - val_acc: 0.9418\n",
      "Epoch 51/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9976 - val_loss: 0.4947 - val_acc: 0.9351\n",
      "Epoch 52/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0041 - acc: 0.9978 - val_loss: 0.4817 - val_acc: 0.9391\n",
      "Epoch 53/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9976 - val_loss: 0.4738 - val_acc: 0.9421\n",
      "Epoch 54/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9981 - val_loss: 0.5019 - val_acc: 0.9366\n",
      "Epoch 55/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0040 - acc: 0.9978 - val_loss: 0.4970 - val_acc: 0.9388\n",
      "Epoch 56/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9983 - val_loss: 0.5228 - val_acc: 0.9341\n",
      "Epoch 57/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0042 - acc: 0.9976 - val_loss: 0.4974 - val_acc: 0.9371\n",
      "Epoch 58/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.4875 - val_acc: 0.9401\n",
      "Epoch 59/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.4996 - val_acc: 0.9398\n",
      "Epoch 60/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9981 - val_loss: 0.5111 - val_acc: 0.9353\n",
      "Epoch 61/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0040 - acc: 0.9976 - val_loss: 0.4981 - val_acc: 0.9383\n",
      "Epoch 62/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9982 - val_loss: 0.5051 - val_acc: 0.9423\n",
      "Epoch 63/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9981 - val_loss: 0.5067 - val_acc: 0.9391\n",
      "Epoch 64/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9976 - val_loss: 0.5222 - val_acc: 0.9383\n",
      "Epoch 65/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9981 - val_loss: 0.5159 - val_acc: 0.9401\n",
      "Epoch 66/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9977 - val_loss: 0.5199 - val_acc: 0.9401\n",
      "Epoch 67/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.4471 - val_acc: 0.9428\n",
      "Epoch 68/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.4200 - val_acc: 0.9418\n",
      "Epoch 69/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0048 - acc: 0.9973 - val_loss: 0.4580 - val_acc: 0.9310\n",
      "Epoch 70/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9979 - val_loss: 0.4873 - val_acc: 0.9285\n",
      "Epoch 71/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9978 - val_loss: 0.4760 - val_acc: 0.9346\n",
      "Epoch 72/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9975 - val_loss: 0.4881 - val_acc: 0.9338\n",
      "Epoch 73/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9980 - val_loss: 0.5143 - val_acc: 0.9278\n",
      "Epoch 74/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.4938 - val_acc: 0.9358\n",
      "Epoch 75/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.5077 - val_acc: 0.9323\n",
      "Epoch 76/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9979 - val_loss: 0.5059 - val_acc: 0.9341\n",
      "Epoch 77/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9979 - val_loss: 0.5212 - val_acc: 0.9313\n",
      "Epoch 78/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.5398 - val_acc: 0.9268\n",
      "Epoch 79/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9973 - val_loss: 0.5148 - val_acc: 0.9318\n",
      "Epoch 80/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0038 - acc: 0.9982 - val_loss: 0.5483 - val_acc: 0.9278\n",
      "Epoch 81/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.5221 - val_acc: 0.9356\n",
      "Epoch 82/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9981 - val_loss: 0.5579 - val_acc: 0.9270\n",
      "Epoch 83/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9975 - val_loss: 0.5352 - val_acc: 0.9325\n",
      "Epoch 84/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.5494 - val_acc: 0.9338\n",
      "Epoch 85/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.5470 - val_acc: 0.9356\n",
      "Epoch 86/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0057 - acc: 0.9973 - val_loss: 0.5057 - val_acc: 0.9293\n",
      "Epoch 87/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0057 - acc: 0.9973 - val_loss: 0.4355 - val_acc: 0.9378\n",
      "Epoch 88/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0039 - acc: 0.9978 - val_loss: 0.4645 - val_acc: 0.9330\n",
      "Epoch 89/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.4798 - val_acc: 0.9310\n",
      "Epoch 90/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9981 - val_loss: 0.4770 - val_acc: 0.9348\n",
      "Epoch 91/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.4804 - val_acc: 0.9368\n",
      "Epoch 92/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.4980 - val_acc: 0.9313\n",
      "Epoch 93/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9977 - val_loss: 0.5009 - val_acc: 0.9318\n",
      "Epoch 94/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9979 - val_loss: 0.5044 - val_acc: 0.9341\n",
      "Epoch 95/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0036 - acc: 0.9976 - val_loss: 0.5086 - val_acc: 0.9330\n",
      "Epoch 96/100\n",
      "16079/16079 [==============================] - 31s 2ms/step - loss: 0.0036 - acc: 0.9978 - val_loss: 0.5166 - val_acc: 0.9313\n",
      "Epoch 97/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0036 - acc: 0.9978 - val_loss: 0.5219 - val_acc: 0.9310\n",
      "Epoch 98/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0037 - acc: 0.9978 - val_loss: 0.5172 - val_acc: 0.9351\n",
      "Epoch 99/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0036 - acc: 0.9979 - val_loss: 0.5274 - val_acc: 0.9363\n",
      "Epoch 100/100\n",
      "16079/16079 [==============================] - 30s 2ms/step - loss: 0.0036 - acc: 0.9980 - val_loss: 0.5322 - val_acc: 0.9363\n",
      "3036.66828584671\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(\n",
    "    train_X, \n",
    "    train_y, \n",
    "    validation_data=(validation_X, validation_y), \n",
    "    epochs=100, \n",
    "    batch_size=64\n",
    ")\n",
    "end = time.time()\n",
    "print(end-start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history.history['loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predictions = model.predict(test_X)\n",
    "validation_y_predictions = model.predict(validation_X)\n",
    "\n",
    "test_y_argmax = np.argmax(test_y,axis=1)\n",
    "validation_y_argmax = np.argmax(validation_y,axis=1)\n",
    "\n",
    "test_y_predictions_argmax = np.argmax(test_y_predictions, axis=1)\n",
    "validation_y_predictions_argmax = np.argmax(validation_y_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99971867e-01, 0.00000000e+00],\n",
       "       [9.97921944e-01, 1.43051147e-06],\n",
       "       [9.99879599e-01, 2.98023224e-08],\n",
       "       [9.99974608e-01, 0.00000000e+00],\n",
       "       [9.99553978e-01, 8.94069672e-08],\n",
       "       [9.99534607e-01, 1.49011612e-07],\n",
       "       [5.84465206e-01, 3.55574489e-03],\n",
       "       [9.98989344e-01, 5.06639481e-07],\n",
       "       [9.05564904e-01, 3.40014696e-04],\n",
       "       [9.80813026e-01, 1.14142895e-05]], dtype=float32)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_predictions_argmax[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_argmax[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       619\n",
      "           1       0.03      0.03      0.03        29\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       648\n",
      "   macro avg       0.49      0.49      0.49       648\n",
      "weighted avg       0.91      0.91      0.91       648\n",
      "\n",
      "[[590  29]\n",
      " [ 28   1]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_argmax, test_y_predictions_argmax))\n",
    "print(confusion_matrix(test_y_argmax, test_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      3872\n",
      "           1       0.05      0.07      0.06       116\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      3988\n",
      "   macro avg       0.51      0.52      0.51      3988\n",
      "weighted avg       0.95      0.94      0.94      3988\n",
      "\n",
      "[[3726  146]\n",
      " [ 108    8]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_y_argmax, validation_y_predictions_argmax))\n",
    "print(confusion_matrix(validation_y_argmax, validation_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual_and_prediction = list(zip(test_y_argmax, test_y_predictions_argmax))\n",
    "[y for i, y in enumerate(y_actual_and_prediction)][80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "25\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20085, 20105, 20106, 20109, 20136, 20138, 20166, 20202, 20211, 20248]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ids_for_false_positives = []\n",
    "log_ids_for_false_negatives = []\n",
    "log_ids_for_true_positives = []\n",
    "offset = index_for_validation_test_split\n",
    "for index, value in enumerate(y_actual_and_prediction):\n",
    "    if value == (0, 1):\n",
    "        log_ids_for_false_positives.append(offset + index)\n",
    "    elif value == (1, 0):\n",
    "        log_ids_for_false_negatives.append(offset + index)\n",
    "    elif value == (1,1):\n",
    "        log_ids_for_true_positives.append(offset + index)\n",
    "    \n",
    "log_ids_for_false_positives = [index_for_validation_test_split + index for index, value in enumerate(y_actual_and_prediction) if value==(0, 1)]\n",
    "log_ids_for_false_positives = [index_for_validation_test_split + index for index, value in enumerate(y_actual_and_prediction) if value==(0, 1)]\n",
    "print(len(log_ids_for_false_positives))\n",
    "print(len(log_ids_for_false_negatives))\n",
    "print(len(log_ids_for_true_positives))\n",
    "log_ids_for_false_positives[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or, for simplicity, print md5.new(string).digest() :)\n",
      "BUT from geas/DBdriver.py:\n",
      "def _make_passkey(self, user, passwd, random):\n",
      "def _hexstr(self, s):\n",
      "but when I update or co, it comes back\n",
      "doesn't jamest have access to the cvs server?\n",
      "either that or I customize interchange\n",
      "(basically Python-based web application services\n",
      "webware and GNUe might be interesting\n",
      "real or imagined\n",
      "any suggestions/comments?\n",
      "doesn't it still have a usenet gateway?\n",
      "and windows isnt a 'monitorless' operating system\n",
      "there is an option to open as access as 97\n",
      "i will get 97 up here pretty quick\n",
      "and be much more 'official' than informal help\n",
      "more official?\n",
      "i.e. accountable\n",
      "any non ie 5.0 or greater browser in fact\n",
      "F*** YOU! No MSN for you.\n",
      "this is really really incredible\n",
      "I always wondered if gnuebot and bigbrother secretly fought in the background\n",
      "either with win2k or kde&linux\n",
      "the major hangup is of course.....drumroll....Office\n",
      "what's it running per seat?\n",
      "I strongly dislike cygwin's setup\n",
      "if exists (select 1 from mdean) print 'hello'\n",
      "BUT we are hitting a wall on something (small wall for now)\n",
      "we are updating 'accounts' 'contacts' to be much more robust and FLEXIBLE\n",
      "bar with products a and b\n",
      "i want foo to only see stuff for x and y and bar with a and b\n",
      "i.e. the customer would never see dcl\n"
     ]
    }
   ],
   "source": [
    "for log_id in log_ids_for_false_positives:\n",
    "    print(get_words_at_line_number(word_indexes, log_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyro is an object system like what gcomm will be\n",
      "the python email client\n",
      "you should be able to access it via geas\n",
      "and todo tool\n"
     ]
    }
   ],
   "source": [
    "for log_id in log_ids_for_true_positives:\n",
    "    print(get_words_at_line_number(word_indexes, log_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btw, why are ou guys calling this abstraction thingy GComm when Dave has a project called GNU Comm (GComm fr short)?\n",
      "as far as I'm concerned, GComm is our internal package name... to the external world, it's GNUe Common\n",
      "but that is a good point\n",
      "by same guys that wrote pygmy\n",
      "I need a production quality GNUe web shopping cart ;-)\n",
      "anything is possible I know, but ideally we need to get ideas on some sort of php and GEAS interface\n",
      "guess I'll just customize interchange.. hopefully actually have it done in a few days\n",
      "our inventory package isn't completed\n",
      "but if you have an inventory package\n",
      "I know a web interface for GNUe Forms is in the works, but I'm sure you need something relatively quickly\n",
      "madlocke was working on that, but as you probably know, he's been out of commission (sick) lately\n",
      "a new release (feature wise) is probably about 3 or 4 weeks away since the db upgrade is going to be huge\n",
      "I may make an interim bug fix/small feature release to get some of the email support down\n",
      "but we are seeing a GREAT value in DCL as a communication tool to customers\n",
      "as well as a billing tool\n",
      "the todo tool works fine\n",
      "but the communication tool is flawed\n",
      "if the accounts dont have same products\n",
      "it should be fairly easy to implement who can view what\n",
      "by product\n",
      "but then the next step becomes billing (or services)\n",
      "at which point products and services need to be 'separate'\n",
      "but that was because i didnt see dcl as a communications tool\n",
      "your use of services sounds like it could be an action\n",
      "as I said, I am going to be working on this stuff (minus billing) for work, so it will come\n"
     ]
    }
   ],
   "source": [
    "for log_id in log_ids_for_false_negatives:\n",
    "    print(get_words_at_line_number(word_indexes, log_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merged Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test_y_predictions = merged_model.predict([test_X, test_features_X])\n",
    "merged_validation_y_predictions = merged_model.predict([validation_X, validation_features_X])\n",
    "\n",
    "merged_test_y_argmax = np.argmax(test_y,axis=1)\n",
    "merged_validation_y_argmax = np.argmax(validation_y,axis=1)\n",
    "\n",
    "merged_test_y_predictions_argmax = np.argmax(merged_test_y_predictions[1], axis=1)\n",
    "merged_validation_y_predictions_argmax = np.argmax(merged_validation_y_predictions[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(merged_test_y_predictions_argmax[:100])\n",
    "# print(merged_test_y_predictions[0])\n",
    "print(merged_test_y_argmax[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       619\n",
      "           1       0.12      0.17      0.14        29\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       648\n",
      "   macro avg       0.54      0.56      0.55       648\n",
      "weighted avg       0.92      0.91      0.92       648\n",
      "\n",
      "[[584  35]\n",
      " [ 24   5]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_test_y_argmax, merged_test_y_predictions_argmax))\n",
    "print(confusion_matrix(merged_test_y_argmax, merged_test_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      3872\n",
      "           1       0.04      0.08      0.05       116\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3988\n",
      "   macro avg       0.50      0.51      0.50      3988\n",
      "weighted avg       0.94      0.92      0.93      3988\n",
      "\n",
      "[[3642  230]\n",
      " [ 107    9]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(merged_validation_y_argmax, merged_validation_y_predictions_argmax))\n",
    "print(confusion_matrix(merged_validation_y_argmax, merged_validation_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"I love machine learning. Its awesome.\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building chatbots\",\n",
    "        \"they chat amagingly well\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(chat_logs[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(chat_logs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_epochs = 100\n",
    "epochs = 40\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "min_alpha = 0.00025\n",
    "min_count = 2\n",
    "\n",
    "# d2v_model = Doc2Vec(\n",
    "#     size=vec_size,\n",
    "#     alpha=alpha, \n",
    "#     min_alpha=min_alpha,\n",
    "#     min_count=1,\n",
    "#     dm =1\n",
    "# )\n",
    "\n",
    "d2v_model = Doc2Vec(vector_size=vec_size, min_count=min_count, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.5 s, sys: 8.59 s, total: 36.1 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%time d2v_model.train(tagged_data, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, max_epochs + 1):\n",
    "#     if epoch % 10 == 0:\n",
    "#         print('iteration {0}'.format(epoch))\n",
    "#     d2v_model.train(tagged_data,\n",
    "#                 total_examples=d2v_model.corpus_count,\n",
    "#                 epochs=d2v_model.epochs)\n",
    "#     # decrease the learning rate\n",
    "#     d2v_model.alpha -= 0.0002\n",
    "#     # fix the learning rate, no decay\n",
    "#     d2v_model.min_alpha = d2v_model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model_filename = join(DATA_FILES_DIR, \"doc2vec_model_10e\")\n",
    "d2v_model.save(d2v_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_d2v_model= Doc2Vec.load(d2v_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1_infer [-0.01366701 -0.02549269  0.05739471  0.0522558  -0.04657764  0.02803853\n",
      " -0.02799745  0.06102591 -0.00764901 -0.01200486 -0.03226999 -0.0479882\n",
      " -0.00444868 -0.08236206 -0.02488584  0.03369953 -0.01224146  0.01957402\n",
      " -0.00447059 -0.02264629]\n"
     ]
    }
   ],
   "source": [
    "test_data = word_tokenize(\"great\".lower())\n",
    "v1 = loaded_d2v_model.infer_vector(test_data, steps=epochs, alpha=alpha, min_alpha=min_alpha)\n",
    "print(\"V1_infer\", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('17774', 0.8790661692619324), ('2020', 0.8772040605545044), ('8091', 0.8742135763168335), ('5032', 0.8663190603256226), ('14376', 0.8627078533172607), ('17677', 0.8586421012878418), ('1800', 0.8579913377761841), ('15340', 0.8560564517974854), ('4970', 0.8550747632980347), ('12065', 0.8510655164718628)]\n"
     ]
    }
   ],
   "source": [
    "# to find most similar doc using tags\n",
    "similar_doc = loaded_d2v_model.docvecs.most_similar(positive=[v1])\n",
    "print(similar_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02454001 -0.03144716 -0.02665585 -0.03217845 -0.03651904  0.02073577\n",
      "  0.02193299 -0.001555   -0.00052284 -0.004239    0.01394437 -0.00971698\n",
      "  0.00216964  0.00106866 -0.0232363   0.0085037  -0.00322458  0.01272531\n",
      "  0.00839755 -0.02420341]\n"
     ]
    }
   ],
   "source": [
    "# to find vector of doc in training data using tags or in other words, \n",
    "# printing the vector of document at index 1 in training data\n",
    "vec_1 = loaded_d2v_model.docvecs['1']\n",
    "print(vec_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_logs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
