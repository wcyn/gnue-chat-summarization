{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Using Keras for Word Embedding as well as the LSTM\n",
    "\n",
    "https://towardsdatascience.com/recurrent-neural-networks-by-example-in-python-ffd204f99470\n",
    "\n",
    "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from app.services.data_preparation import get_processed_data_sets_for_model, DATA_FILES_DIR, TIME_OFFSET\n",
    "from app.services.sentence_tokenizer import get_chat_log_sequences, MAX_CHAT_LENGTH, TOP_WORDS\n",
    "from keras.layers import Bidirectional, Dense, Dropout, Input, LSTM, TimeDistributed, LeakyReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "processed_data, data_type_log_ids, train_validation_and_test_dates = get_processed_data_sets_for_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>0.997990</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208406</td>\n",
       "      <td>0.025535</td>\n",
       "      <td>0.057232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>0.998492</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>0.685186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>0.998995</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233131</td>\n",
       "      <td>0.015752</td>\n",
       "      <td>0.259289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>0.999497</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656124</td>\n",
       "      <td>0.034522</td>\n",
       "      <td>0.501867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230761</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.077018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "3572                    0.997990         0.158730                      0.0   \n",
       "3573                    0.998492         0.015873                      0.0   \n",
       "3574                    0.998995         0.031746                      0.0   \n",
       "3575                    0.999497         0.015873                      0.0   \n",
       "3576                    1.000000         0.095238                      0.0   \n",
       "\n",
       "      sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "3572         0.208406                0.025535                0.057232  \n",
       "3573         0.000000                0.016537                0.685186  \n",
       "3574         0.233131                0.015752                0.259289  \n",
       "3575         0.656124                0.034522                0.501867  \n",
       "3576         0.230761                0.030084                0.077018  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[\"validation_features_X\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
      "13728                    0.992537         0.082192                 0.027027   \n",
      "13729                    0.994403         0.000000                 0.000000   \n",
      "13730                    0.996269         0.438356                 0.027027   \n",
      "13731                    0.998134         0.027397                 0.027027   \n",
      "13732                    1.000000         0.041096                 0.000000   \n",
      "\n",
      "       sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
      "13728         0.680659                0.007117                0.100894  \n",
      "13729         0.481478                0.000000                0.000000  \n",
      "13730         0.714451                0.006696                0.017713  \n",
      "13731         0.481478                0.004437                0.322041  \n",
      "13732         0.000000                0.004600                0.209270  \n",
      "(3405, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_sentence_position</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>number_of_special_terms</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>normalized_mean_tf_idf</th>\n",
       "      <th>normalized_mean_tf_isf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.368636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.114519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.260825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.098592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.086599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160904</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.665037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_sentence_position  sentence_length  number_of_special_terms  \\\n",
       "0                    0.001182         0.028169                 0.142857   \n",
       "1                    0.002364         0.084507                 0.285714   \n",
       "2                    0.003546         0.028169                 0.000000   \n",
       "3                    0.004728         0.098592                 0.000000   \n",
       "4                    0.005910         0.014085                 0.000000   \n",
       "\n",
       "   sentiment_score  normalized_mean_tf_idf  normalized_mean_tf_isf  \n",
       "0         0.000000                0.005692                0.368636  \n",
       "1         0.000000                0.007438                0.114519  \n",
       "2         0.000000                0.006591                0.260825  \n",
       "3         0.000000                0.011325                0.086599  \n",
       "4         0.160904                0.006633                0.665037  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_X = processed_data[\"train_features_X\"]\n",
    "validation_features_X = processed_data[\"validation_features_X\"]\n",
    "test_features_X = processed_data[\"test_features_X\"]\n",
    "print(train_features_X.tail())\n",
    "\n",
    "assert train_features_X.shape[1] == test_features_X.shape[1] \n",
    "assert test_features_X.shape[1] == validation_features_X.shape[1] \n",
    "print(test_features_X.shape)\n",
    "test_features_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13733, 100)\n",
      "(3405, 100)\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    4 1359   18  108   15    3 4900  918   12  115\n",
      "   786   14]]\n",
      "3405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hey reinhard\\n', 'did jonas ever hack on GNUe?\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_chat_logs = get_chat_log_sequences(data_type_log_ids[\"train\"])\n",
    "validation_X, validation_chat_logs = get_chat_log_sequences(data_type_log_ids[\"validation\"])\n",
    "test_X, test_chat_logs = get_chat_log_sequences(data_type_log_ids[\"test\"])\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_X[:1])\n",
    "print(len(test_X))\n",
    "test_chat_logs[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3405, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = processed_data[\"train_y\"]\n",
    "validation_y = processed_data[\"validation_y\"]\n",
    "test_y = processed_data[\"test_y\"]\n",
    "print(test_y.shape)\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[144080, 144081, 144082, 144083, 144084]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type_log_ids[\"test\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_labels = [0 if list(label) == [1, 0] else 1 for label in train_y]\n",
    "train_y_labels[60: 80]\n",
    "np.unique(train_y_labels)\n",
    "# j = [1,0]\n",
    "# j == [1,0]\n",
    "# list(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/wcyn/anaconda3/envs/gnue-irc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Sentence input: meant to receive sequences of `max_chat_length` integers, between 1 and `top_words`.\n",
    "main_sentence_input = Input(shape=(MAX_CHAT_LENGTH,), dtype='int32', name='main_sentence_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=TOP_WORDS, input_length=MAX_CHAT_LENGTH)(main_sentence_input)\n",
    "\n",
    "# An LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51756237, 14.73497854])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    np.unique(train_y_labels),\n",
    "    train_y_labels\n",
    ")\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 70\n",
    "BATCH_SIZE = 128\n",
    "OPTIMIZER = \"rmsprop\"\n",
    "OUTPUT_ACTIVATION = \"sigmoid\"\n",
    "# Here we insert the auxiliary loss, allowing the LSTM and Embedding layer \n",
    "# to be trained smoothly even though the main loss will be much higher in the model.\n",
    "auxiliary_output = Dense(2, activation=OUTPUT_ACTIVATION, name='aux_output')(lstm_out)\n",
    "\n",
    "# At this point, we feed into the model our auxiliary input data by \n",
    "# concatenating it with the LSTM output\n",
    "num_of_feature_columns = test_features_X.shape[1]\n",
    "sentence_features_input = Input(shape=(num_of_feature_columns,), name='sentence_features_input')\n",
    "merged_input_and_output = keras.layers.concatenate([lstm_out, sentence_features_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(merged_input_and_output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(2, activation=OUTPUT_ACTIVATION, name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a model with two inputs and two outputs\n",
    "merged_model = Model(\n",
    "    inputs=[main_sentence_input, sentence_features_input], \n",
    "    outputs=[main_output, auxiliary_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_sentence_input (InputLayer (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 512)     51200000    main_sentence_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           69760       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sentence_features_input (InputL (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 38)           0           lstm_1[0][0]                     \n",
      "                                                                 sentence_features_input[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           2496        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64)           4160        dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           4160        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            130         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 2)            66          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 51,280,772\n",
      "Trainable params: 51,280,772\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "merged_model.compile(\n",
    "    optimizer=OPTIMIZER, \n",
    "    #optimizer=\"adam\",\n",
    "    loss='categorical_crossentropy',\n",
    "    #loss_weights=[1., 0.2]\n",
    ")\n",
    "merged_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13733 samples, validate on 3577 samples\n",
      "Epoch 1/70\n",
      "13733/13733 [==============================] - 78s 6ms/step - loss: 0.0178 - main_output_loss: 0.0117 - aux_output_loss: 0.0060 - val_loss: 3.7983 - val_main_output_loss: 2.6700 - val_aux_output_loss: 1.1284\n",
      "Epoch 2/70\n",
      "13733/13733 [==============================] - 78s 6ms/step - loss: 0.0075 - main_output_loss: 0.0041 - aux_output_loss: 0.0034 - val_loss: 3.3078 - val_main_output_loss: 2.2878 - val_aux_output_loss: 1.0200\n",
      "Epoch 3/70\n",
      "13733/13733 [==============================] - 77s 6ms/step - loss: 0.0065 - main_output_loss: 0.0034 - aux_output_loss: 0.0032 - val_loss: 4.0406 - val_main_output_loss: 2.8955 - val_aux_output_loss: 1.1452\n",
      "Epoch 4/70\n",
      "13733/13733 [==============================] - 77s 6ms/step - loss: 0.0059 - main_output_loss: 0.0028 - aux_output_loss: 0.0031 - val_loss: 3.5229 - val_main_output_loss: 2.4982 - val_aux_output_loss: 1.0247\n",
      "Epoch 5/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0087 - main_output_loss: 0.0051 - aux_output_loss: 0.0036 - val_loss: 3.6665 - val_main_output_loss: 2.4356 - val_aux_output_loss: 1.2309\n",
      "Epoch 6/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0065 - main_output_loss: 0.0034 - aux_output_loss: 0.0031 - val_loss: 2.7808 - val_main_output_loss: 1.8185 - val_aux_output_loss: 0.9623\n",
      "Epoch 7/70\n",
      "13733/13733 [==============================] - 78s 6ms/step - loss: 0.0060 - main_output_loss: 0.0030 - aux_output_loss: 0.0030 - val_loss: 3.7522 - val_main_output_loss: 2.6335 - val_aux_output_loss: 1.1188\n",
      "Epoch 8/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0061 - main_output_loss: 0.0030 - aux_output_loss: 0.0031 - val_loss: 4.1600 - val_main_output_loss: 2.9113 - val_aux_output_loss: 1.2487\n",
      "Epoch 9/70\n",
      "13733/13733 [==============================] - 78s 6ms/step - loss: 0.0061 - main_output_loss: 0.0031 - aux_output_loss: 0.0031 - val_loss: 3.4684 - val_main_output_loss: 2.4030 - val_aux_output_loss: 1.0655\n",
      "Epoch 10/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0057 - main_output_loss: 0.0028 - aux_output_loss: 0.0030 - val_loss: 4.0175 - val_main_output_loss: 2.8040 - val_aux_output_loss: 1.2135\n",
      "Epoch 11/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0067 - main_output_loss: 0.0035 - aux_output_loss: 0.0032 - val_loss: 3.2524 - val_main_output_loss: 2.1821 - val_aux_output_loss: 1.0703\n",
      "Epoch 12/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0086 - main_output_loss: 0.0048 - aux_output_loss: 0.0038 - val_loss: 2.9349 - val_main_output_loss: 1.7727 - val_aux_output_loss: 1.1621\n",
      "Epoch 13/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0088 - main_output_loss: 0.0051 - aux_output_loss: 0.0037 - val_loss: 2.9957 - val_main_output_loss: 1.9281 - val_aux_output_loss: 1.0676\n",
      "Epoch 14/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0058 - main_output_loss: 0.0029 - aux_output_loss: 0.0029 - val_loss: 3.3761 - val_main_output_loss: 2.2047 - val_aux_output_loss: 1.1714\n",
      "Epoch 15/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0074 - main_output_loss: 0.0041 - aux_output_loss: 0.0034 - val_loss: 3.2433 - val_main_output_loss: 2.1562 - val_aux_output_loss: 1.0871\n",
      "Epoch 16/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: 0.0062 - main_output_loss: 0.0031 - aux_output_loss: 0.0031 - val_loss: 2.6559 - val_main_output_loss: 1.6762 - val_aux_output_loss: 0.9797\n",
      "Epoch 17/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0059 - main_output_loss: 0.0029 - aux_output_loss: 0.0030 - val_loss: 2.9931 - val_main_output_loss: 1.8720 - val_aux_output_loss: 1.1211\n",
      "Epoch 18/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0067 - main_output_loss: 0.0035 - aux_output_loss: 0.0032 - val_loss: 3.0032 - val_main_output_loss: 1.8878 - val_aux_output_loss: 1.1154\n",
      "Epoch 19/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0061 - main_output_loss: 0.0030 - aux_output_loss: 0.0031 - val_loss: 3.3237 - val_main_output_loss: 2.1188 - val_aux_output_loss: 1.2049\n",
      "Epoch 20/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0065 - main_output_loss: 0.0033 - aux_output_loss: 0.0032 - val_loss: 3.0341 - val_main_output_loss: 1.9343 - val_aux_output_loss: 1.0999\n",
      "Epoch 21/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0078 - main_output_loss: 0.0042 - aux_output_loss: 0.0036 - val_loss: 2.7012 - val_main_output_loss: 1.7091 - val_aux_output_loss: 0.9921\n",
      "Epoch 22/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0059 - main_output_loss: 0.0029 - aux_output_loss: 0.0030 - val_loss: 2.9561 - val_main_output_loss: 1.9117 - val_aux_output_loss: 1.0444\n",
      "Epoch 23/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: 0.0059 - main_output_loss: 0.0028 - aux_output_loss: 0.0031 - val_loss: 3.1594 - val_main_output_loss: 2.0272 - val_aux_output_loss: 1.1322\n",
      "Epoch 24/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: 0.0061 - main_output_loss: 0.0030 - aux_output_loss: 0.0031 - val_loss: 2.8929 - val_main_output_loss: 1.8500 - val_aux_output_loss: 1.0429\n",
      "Epoch 25/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0061 - main_output_loss: 0.0032 - aux_output_loss: 0.0030 - val_loss: 2.8753 - val_main_output_loss: 1.8256 - val_aux_output_loss: 1.0497\n",
      "Epoch 26/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0062 - main_output_loss: 0.0031 - aux_output_loss: 0.0031 - val_loss: 3.0848 - val_main_output_loss: 1.9273 - val_aux_output_loss: 1.1575\n",
      "Epoch 27/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0060 - main_output_loss: 0.0031 - aux_output_loss: 0.0029 - val_loss: 2.8515 - val_main_output_loss: 1.7816 - val_aux_output_loss: 1.0699\n",
      "Epoch 28/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0084 - main_output_loss: 0.0045 - aux_output_loss: 0.0038 - val_loss: 2.8729 - val_main_output_loss: 1.7706 - val_aux_output_loss: 1.1023\n",
      "Epoch 29/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0060 - main_output_loss: 0.0030 - aux_output_loss: 0.0030 - val_loss: 2.9314 - val_main_output_loss: 1.8260 - val_aux_output_loss: 1.1053\n",
      "Epoch 30/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0059 - main_output_loss: 0.0029 - aux_output_loss: 0.0030 - val_loss: 3.0041 - val_main_output_loss: 1.8492 - val_aux_output_loss: 1.1548\n",
      "Epoch 31/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0061 - main_output_loss: 0.0030 - aux_output_loss: 0.0031 - val_loss: 3.2907 - val_main_output_loss: 2.1064 - val_aux_output_loss: 1.1844\n",
      "Epoch 32/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0057 - main_output_loss: 0.0027 - aux_output_loss: 0.0029 - val_loss: 3.2732 - val_main_output_loss: 2.1246 - val_aux_output_loss: 1.1486\n",
      "Epoch 33/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0084 - main_output_loss: 0.0048 - aux_output_loss: 0.0037 - val_loss: 2.8966 - val_main_output_loss: 1.7636 - val_aux_output_loss: 1.1330\n",
      "Epoch 34/70\n",
      "13733/13733 [==============================] - 77s 6ms/step - loss: 0.0060 - main_output_loss: 0.0030 - aux_output_loss: 0.0030 - val_loss: 2.7746 - val_main_output_loss: 1.6699 - val_aux_output_loss: 1.1047\n",
      "Epoch 35/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0061 - main_output_loss: 0.0031 - aux_output_loss: 0.0030 - val_loss: 3.2262 - val_main_output_loss: 2.0305 - val_aux_output_loss: 1.1958\n",
      "Epoch 36/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: 0.0065 - main_output_loss: 0.0033 - aux_output_loss: 0.0031 - val_loss: 3.0101 - val_main_output_loss: 1.8642 - val_aux_output_loss: 1.1458\n",
      "Epoch 37/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0068 - main_output_loss: 0.0038 - aux_output_loss: 0.0030 - val_loss: 2.5937 - val_main_output_loss: 1.6725 - val_aux_output_loss: 0.9212\n",
      "Epoch 38/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13733/13733 [==============================] - 78s 6ms/step - loss: 0.0077 - main_output_loss: 0.0044 - aux_output_loss: 0.0033 - val_loss: 3.2461 - val_main_output_loss: 2.0373 - val_aux_output_loss: 1.2088\n",
      "Epoch 39/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: 0.0062 - main_output_loss: 0.0030 - aux_output_loss: 0.0032 - val_loss: 3.1328 - val_main_output_loss: 1.9963 - val_aux_output_loss: 1.1365\n",
      "Epoch 40/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0059 - main_output_loss: 0.0029 - aux_output_loss: 0.0030 - val_loss: 3.3764 - val_main_output_loss: 2.1102 - val_aux_output_loss: 1.2662\n",
      "Epoch 41/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0085 - main_output_loss: 0.0045 - aux_output_loss: 0.0040 - val_loss: 2.9905 - val_main_output_loss: 1.9274 - val_aux_output_loss: 1.0631\n",
      "Epoch 42/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0061 - main_output_loss: 0.0031 - aux_output_loss: 0.0031 - val_loss: 2.7005 - val_main_output_loss: 1.6783 - val_aux_output_loss: 1.0222\n",
      "Epoch 43/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0067 - main_output_loss: 0.0034 - aux_output_loss: 0.0032 - val_loss: 3.0070 - val_main_output_loss: 1.8404 - val_aux_output_loss: 1.1666\n",
      "Epoch 44/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: 0.0061 - main_output_loss: 0.0032 - aux_output_loss: 0.0030 - val_loss: 3.1750 - val_main_output_loss: 2.0319 - val_aux_output_loss: 1.1431\n",
      "Epoch 45/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: 0.0061 - main_output_loss: 0.0030 - aux_output_loss: 0.0030 - val_loss: 2.8816 - val_main_output_loss: 1.7541 - val_aux_output_loss: 1.1274\n",
      "Epoch 46/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 47/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 48/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 49/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 50/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 51/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 52/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 53/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 54/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 55/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 56/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 57/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 58/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 59/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 60/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 61/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 62/70\n",
      "13733/13733 [==============================] - 81s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 63/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 64/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 65/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 66/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 67/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 68/70\n",
      "13733/13733 [==============================] - 79s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 69/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "Epoch 70/70\n",
      "13733/13733 [==============================] - 80s 6ms/step - loss: nan - main_output_loss: nan - aux_output_loss: nan - val_loss: nan - val_main_output_loss: nan - val_aux_output_loss: nan\n",
      "5569.044069051743  seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the model by passing it lists of input arrays and target arrays 19960.996418952942  seconds\n",
    "# 25183.798012971878  seconds Second time, with 30 minute break in between\n",
    "start = time.time()\n",
    "merged_model_history = merged_model.fit(\n",
    "    [train_X, train_features_X], \n",
    "    [train_y, train_y],\n",
    "    #validation_split=0.2,\n",
    "    validation_data=[\n",
    "        [validation_X, validation_features_X], \n",
    "        [validation_y, validation_y]\n",
    "    ],\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    #class_weight=[class_weights, class_weights]\n",
    ")\n",
    "end = time.time()\n",
    "time_taken_in_minutes = (end-start)//60\n",
    "print(end - start, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_model_loss_values = merged_model_history.history['loss']\n",
    "merged_model_epochs = range(1, len(merged_model_loss_values)+1)\n",
    "\n",
    "plt.plot(merged_model_epochs, merged_model_loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524213"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_now = time.time()\n",
    "month_day =time.strftime(\"%m-%d\")\n",
    "time_diff = int(time_now-TIME_OFFSET)\n",
    "time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../feature_extraction/data_files/models/04-08d_524213df_70e_128bs_rmsprop_92min_merged_hybrid_model.h5'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current_time = time.strftime(\"%Y-%m-%d-(%H_%M_%S)\")\n",
    "merged_model_filename = month_day + \"d_{}df_{}e_{}bs_{}_{}min\".format(\n",
    "    time_diff, \n",
    "    EPOCHS, \n",
    "    BATCH_SIZE, \n",
    "    OPTIMIZER,\n",
    "    int(time_taken_in_minutes)\n",
    ")\n",
    "MODELS_DIR = join(DATA_FILES_DIR, \"models\")\n",
    "merged_model_filename = join(MODELS_DIR,  merged_model_filename + '_merged_hybrid_model.h5')\n",
    "merged_model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "merged_model.save(merged_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "loaded_merged_model = load_model(merged_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "test_y_predictions = loaded_merged_model.predict([test_X, test_features_X])\n",
    "validation_y_predictions = loaded_merged_model.predict([validation_X, validation_features_X])\n",
    "\n",
    "test_y_argmax = np.argmax(test_y,axis=1)\n",
    "validation_y_argmax = np.argmax(validation_y,axis=1)\n",
    "\n",
    "test_y_predictions_argmax = np.argmax(test_y_predictions[1], axis=1)\n",
    "validation_y_predictions_argmax = np.argmax(validation_y_predictions[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        ...,\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=float32), array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        ...,\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=float32)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_predictions_argmax[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_argmax[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3282\n",
      "           1       0.00      0.00      0.00       123\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3405\n",
      "   macro avg       0.48      0.50      0.49      3405\n",
      "weighted avg       0.93      0.96      0.95      3405\n",
      "\n",
      "[[3282    0]\n",
      " [ 123    0]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_argmax, test_y_predictions_argmax))\n",
    "print(confusion_matrix(test_y_argmax, test_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {},
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARIES\n",
      "---------\n",
      " where you planning a single exception raised to the app level or should I make forms handle the various errors at the app level\n",
      "it's because the event system can't keep up with the movement\n",
      "I'm going to make the provider='odbc' and take all the special meaning out of it\n",
      "what's next big ticket in designer?\n",
      "need to clean up the UI system\n",
      "... add drag and drop support for automatically pulling fields/datasources\n",
      "... generalize the designer code so that it can be used w/reports/etc\n",
      "... use BOA (if installed) for code editing\n",
      "insert a duplicate key into table\n",
      "gnuef used to generate pop up dialogs and recover when a dberror was encountered\n",
      "say I query 10 records\n",
      "I have a resultset with 10 recordsets\n",
      "I change the first 3 \n",
      "which causes the _updateFlag's to be set on those records\n",
      "and I insert a new record at the end\n",
      "I go to commit the changes\n",
      "and it performs the updates on the first 3\n",
      "and resets the _updateFlag (since they've been updated)\n",
      "then inserts the last one\n",
      "but it generates an error\n",
      "so\n",
      "PREDICTIONS\n",
      "-----------\n",
      " \n",
      "ROUGE Scores\n",
      "------------\n",
      "Evaluation with Avg\n",
      "\trouge-1:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n",
      "\trouge-2:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n",
      "\trouge-3:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n",
      "\trouge-4:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n",
      "\trouge-l:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n",
      "\trouge-w:\tP: 0.000000\tR: 0.000000\tF1: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from rouge_metrics import *\n",
    "from get_sentences_from_line_numbers import *\n",
    "\n",
    "predicted_chat_logs = [test_chat_logs[index] for index, value in enumerate(test_y_predictions_argmax) if value==1]\n",
    "summaries_chat_logs = [test_chat_logs[index] for index, value in enumerate(test_y_argmax) if value==1]\n",
    "\n",
    "predicted_chat_logs = \"\".join(log for log in predicted_chat_logs)\n",
    "summaries_chat_logs = \"\".join(log for log in summaries_chat_logs)\n",
    "print(\"SUMMARIES\\n---------\\n\", summaries_chat_logs[:1000])\n",
    "print(\"PREDICTIONS\\n-----------\\n\", predicted_chat_logs[:1000])\n",
    "\n",
    "hypotheses = [predicted_chat_logs]\n",
    "references = [summaries_chat_logs]\n",
    "print(\"ROUGE Scores\\n------------\")\n",
    "print_rouge_results(get_rouge_results(hypotheses, references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3513\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3577\n",
      "   macro avg       0.49      0.50      0.50      3577\n",
      "weighted avg       0.96      0.98      0.97      3577\n",
      "\n",
      "[[3513    0]\n",
      " [  64    0]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_y_argmax, validation_y_predictions_argmax))\n",
    "print(confusion_matrix(validation_y_argmax, validation_y_predictions_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
